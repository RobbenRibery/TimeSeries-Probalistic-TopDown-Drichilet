{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.insert(0, '../src/')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from hts.hierarchy import HierarchyTree \n",
    "from datetime import datetime \n",
    "import torch \n",
    "\n",
    "\n",
    "import proption_model \n",
    "import hierachy_encoding \n",
    "import utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('../data/sales_train_validation.csv')\n",
    "sales_train_evaluation = pd.read_csv('../data/sales_train_evaluation.csv') \n",
    "calender = pd.read_csv('../data/calendar.csv') \n",
    "date_to_d = dict(zip(calender.date, calender.d)) \n",
    "d_to_date = dict(zip(calender.d, calender.date)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent nodes sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913,)\n"
     ]
    }
   ],
   "source": [
    "parent_sales = sales_train_validation[sales_train_validation.columns[6:]].sum(axis=0).values\n",
    "print(parent_sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hie EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
       "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
       "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
       "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "1       0       0       0       0       0  \n",
       "2       0       2       3       0       1  \n",
       "3       1       3       0       2       6  \n",
       "4       0       0       2       1       0  \n",
       "\n",
       "[5 rows x 1947 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30490, 1947)\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_evaluation.shape)\n",
    "print(sales_train_evaluation.columns[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_list = ['state_id','store_id','cat_id','dept_id','item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully encoded hierachy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CA</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CA_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WI</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">WI_3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD_2</th>\n",
       "      <th>HOUSEHOLD_2_512</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_513</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_514</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         id\n",
       "state_id store_id cat_id    dept_id     item_id            \n",
       "CA       CA_1     FOODS     FOODS_1     FOODS_1_001       1\n",
       "                                        FOODS_1_002       1\n",
       "                                        FOODS_1_003       1\n",
       "                                        FOODS_1_004       1\n",
       "                                        FOODS_1_005       1\n",
       "...                                                      ..\n",
       "WI       WI_3     HOUSEHOLD HOUSEHOLD_2 HOUSEHOLD_2_512   1\n",
       "                                        HOUSEHOLD_2_513   1\n",
       "                                        HOUSEHOLD_2_514   1\n",
       "                                        HOUSEHOLD_2_515   1\n",
       "                                        HOUSEHOLD_2_516   1\n",
       "\n",
       "[30490 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup = sales_train_evaluation.groupby(groupby_list[:]).count()[['id']]\n",
    "hierachy_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierachy_lookup.loc[('CA','CA_1','FOODS','FOODS_1')].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Partially encoded hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id\n",
       "cat_id dept_id item_id        \n",
       "FOODS  FOODS_1 FOODS_1_001  10\n",
       "               FOODS_1_002  10\n",
       "               FOODS_1_003  10\n",
       "               FOODS_1_004  10\n",
       "               FOODS_1_005  10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2 = sales_train_evaluation.groupby(groupby_list[2:]).count()[['id']]\n",
    "hierachy_lookup_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD_2</th>\n",
       "      <th>HOUSEHOLD_2_512</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_513</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_514</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_515</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3049 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id\n",
       "cat_id    dept_id     item_id            \n",
       "FOODS     FOODS_1     FOODS_1_001      10\n",
       "                      FOODS_1_002      10\n",
       "                      FOODS_1_003      10\n",
       "                      FOODS_1_004      10\n",
       "                      FOODS_1_005      10\n",
       "...                                    ..\n",
       "HOUSEHOLD HOUSEHOLD_2 HOUSEHOLD_2_512  10\n",
       "                      HOUSEHOLD_2_513  10\n",
       "                      HOUSEHOLD_2_514  10\n",
       "                      HOUSEHOLD_2_515  10\n",
       "                      HOUSEHOLD_2_516  10\n",
       "\n",
       "[3049 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TS encoding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierachy_lookup_2 = hierachy_lookup_2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOODS_3        823\n",
       "HOUSEHOLD_1    532\n",
       "HOUSEHOLD_2    515\n",
       "HOBBIES_1      416\n",
       "FOODS_2        398\n",
       "FOODS_1        216\n",
       "HOBBIES_2      149\n",
       "Name: dept_id, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2.dept_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FOODS': 0, 'HOBBIES': 1, 'HOUSEHOLD': 2}\n",
      "{'FOODS_1': 3, 'FOODS_2': 4, 'FOODS_3': 5, 'HOBBIES_1': 6, 'HOBBIES_2': 7, 'HOUSEHOLD_1': 8, 'HOUSEHOLD_2': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hierachy_with_encoded_columns = hierachy_encoding.hie_encoder(hierachy_lookup_2, ['cat_id','dept_id','item_id'])\n",
    "\n",
    "root_to_index = {'root':0}\n",
    "\n",
    "cat_to_dix = dict(zip(hierachy_with_encoded_columns.cat_id,hierachy_with_encoded_columns.cat_id_))\n",
    "print(cat_to_dix)\n",
    "\n",
    "\n",
    "dep_to_dix = dict(zip(hierachy_with_encoded_columns.dept_id,hierachy_with_encoded_columns.dept_id_))\n",
    "print(dep_to_dix)\n",
    "\n",
    "item_to_dix = dict(zip(hierachy_with_encoded_columns.item_id,hierachy_with_encoded_columns.item_id_))\n",
    "#print(item_to_dix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060\n"
     ]
    }
   ],
   "source": [
    "ts_to_index = {}\n",
    "for dic in [root_to_index, cat_to_dix, dep_to_dix, item_to_dix]:\n",
    "    ts_to_index.update(dic)\n",
    "print(len(ts_to_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3059\n"
     ]
    }
   ],
   "source": [
    "inde_to_ts = dict(zip(ts_to_index.values(), ts_to_index.keys()))\n",
    "print(len(inde_to_ts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'FOODS_1': 0,\n",
       "             'FOODS_2': 0,\n",
       "             'FOODS_3': 0,\n",
       "             'HOBBIES_1': 1,\n",
       "             'HOBBIES_2': 1,\n",
       "             'HOUSEHOLD_1': 2,\n",
       "             'HOUSEHOLD_2': 2})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_parent_index = hierachy_encoding.get_parent_index(dep_to_dix, cat_to_dix)\n",
    "dep_parent_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_parent_index = hierachy_encoding.get_parent_index(item_to_dix, dep_to_dix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- Need to constrcut a grpah here, proceeed to next step first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'root': [0, 1, 2]})"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_encoding.get_children_index(cat_to_dix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick a particular familry to construct one training data points \n",
    "    - Parent node - 0 \n",
    "    - Children node - 1, 2, 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect parent sales \n",
    "yp = sales_train_validation.sum(axis=0)[6:].values.reshape(-1,1)# np array \n",
    "yp = yp.T \n",
    "print(yp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOODS</th>\n",
       "      <td>23178</td>\n",
       "      <td>22758</td>\n",
       "      <td>17174</td>\n",
       "      <td>18878</td>\n",
       "      <td>14603</td>\n",
       "      <td>22093</td>\n",
       "      <td>20490</td>\n",
       "      <td>27751</td>\n",
       "      <td>24862</td>\n",
       "      <td>18901</td>\n",
       "      <td>...</td>\n",
       "      <td>28682</td>\n",
       "      <td>32007</td>\n",
       "      <td>34497</td>\n",
       "      <td>26151</td>\n",
       "      <td>24948</td>\n",
       "      <td>23632</td>\n",
       "      <td>23317</td>\n",
       "      <td>26704</td>\n",
       "      <td>31927</td>\n",
       "      <td>32654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES</th>\n",
       "      <td>3764</td>\n",
       "      <td>3357</td>\n",
       "      <td>2682</td>\n",
       "      <td>2669</td>\n",
       "      <td>1814</td>\n",
       "      <td>3220</td>\n",
       "      <td>2944</td>\n",
       "      <td>3986</td>\n",
       "      <td>2899</td>\n",
       "      <td>2615</td>\n",
       "      <td>...</td>\n",
       "      <td>3786</td>\n",
       "      <td>4634</td>\n",
       "      <td>4820</td>\n",
       "      <td>3323</td>\n",
       "      <td>3787</td>\n",
       "      <td>3472</td>\n",
       "      <td>3353</td>\n",
       "      <td>4085</td>\n",
       "      <td>4787</td>\n",
       "      <td>4683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD</th>\n",
       "      <td>5689</td>\n",
       "      <td>5634</td>\n",
       "      <td>3927</td>\n",
       "      <td>3865</td>\n",
       "      <td>2729</td>\n",
       "      <td>3898</td>\n",
       "      <td>4576</td>\n",
       "      <td>6195</td>\n",
       "      <td>4975</td>\n",
       "      <td>4056</td>\n",
       "      <td>...</td>\n",
       "      <td>9321</td>\n",
       "      <td>11721</td>\n",
       "      <td>12323</td>\n",
       "      <td>8585</td>\n",
       "      <td>8835</td>\n",
       "      <td>8239</td>\n",
       "      <td>8363</td>\n",
       "      <td>9728</td>\n",
       "      <td>12248</td>\n",
       "      <td>12458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             d_1    d_2    d_3    d_4    d_5    d_6    d_7    d_8    d_9  \\\n",
       "cat_id                                                                     \n",
       "FOODS      23178  22758  17174  18878  14603  22093  20490  27751  24862   \n",
       "HOBBIES     3764   3357   2682   2669   1814   3220   2944   3986   2899   \n",
       "HOUSEHOLD   5689   5634   3927   3865   2729   3898   4576   6195   4975   \n",
       "\n",
       "            d_10  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  \\\n",
       "cat_id            ...                                                           \n",
       "FOODS      18901  ...   28682   32007   34497   26151   24948   23632   23317   \n",
       "HOBBIES     2615  ...    3786    4634    4820    3323    3787    3472    3353   \n",
       "HOUSEHOLD   4056  ...    9321   11721   12323    8585    8835    8239    8363   \n",
       "\n",
       "           d_1911  d_1912  d_1913  \n",
       "cat_id                             \n",
       "FOODS       26704   31927   32654  \n",
       "HOBBIES      4085    4787    4683  \n",
       "HOUSEHOLD    9728   12248   12458  \n",
       "\n",
       "[3 rows x 1913 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_validation.groupby('cat_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect the proportinos \n",
    "ac = sales_train_validation.groupby('cat_id').sum().values/yp\n",
    "print(ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect the embedding layer input \n",
    "ec = np.array(hierachy_encoding.get_children_index(cat_to_dix)['root']).reshape(-1,1)\n",
    "ec = np.repeat(ec, 1913, axis=1)\n",
    "print(ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913, 3)\n",
      "0\n",
      "(1913, 3)\n",
      "1\n",
      "(1913, 3)\n",
      "2\n",
      "(1913, 3)\n"
     ]
    }
   ],
   "source": [
    "if ac.shape[0] == ec.shape[0]: \n",
    "\n",
    "    input = np.empty(\n",
    "        \n",
    "        (ac.shape[0], ac.shape[1], 3), \n",
    "    \n",
    "    )\n",
    "    print(input.shape)\n",
    "\n",
    "    for c in range(input.shape[0]): \n",
    "        print(c)\n",
    "        # print(yp.T.shape)\n",
    "        # print(ac[c].reshape(-1,1).shape)\n",
    "        # print(ec[c].reshape(-1,1).shape)\n",
    "        input[c] = np.concatenate(\n",
    "            [\n",
    "                ac[c].reshape(-1,1), \n",
    "                yp.T, \n",
    "                ## ---- PLACE HOLDER FOR COVARIATES X ---- ## \n",
    "                ## ---- PLACE HOLDER FOR COVARIATES X ---- ## \n",
    "                ec[c].reshape(-1,1),\n",
    "            ], \n",
    "            axis = 1 \n",
    "        )\n",
    "        print(input[c].shape)    \n",
    "else: \n",
    "    raise \"size of children in embedding does not agree with size of the children in proportions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Time batched input --------\n",
      "(1893, 3, 21, 3)\n",
      "-------- X, y split ------------\n",
      "X input shape is (1893, 3, 14, 3)\n",
      "y input shape is (1893, 3, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "## time batching \n",
    "# dimension about the dataset\n",
    "print('------- Time batched input --------')\n",
    "History = 14\n",
    "Forward = 7\n",
    "\n",
    "number_observations = input.shape[1] - (History + Forward) + 1\n",
    "\n",
    "input_time_batched = np.empty(\n",
    "    (number_observations,input.shape[0], History + Forward, input.shape[-1])\n",
    ")\n",
    "\n",
    "for i in range(number_observations):\n",
    "\n",
    "    input_time_batched[i] = np.array(input[:, i:i + History + Forward, :])\n",
    "\n",
    "print(input_time_batched.shape)\n",
    "# print(input_time_batched[0][0])\n",
    "\n",
    "print(\"-------- X, y split ------------\")\n",
    "input_array = np.empty((\n",
    "    number_observations,\n",
    "    input.shape[0],\n",
    "    History,\n",
    "    input.shape[-1])\n",
    ")\n",
    "\n",
    "target_array = np.empty((\n",
    "    number_observations,\n",
    "    input.shape[0],\n",
    "    Forward,\n",
    "    1)\n",
    ")\n",
    "\n",
    "# print(input_tensor.shape)\n",
    "# print(target_tensor.shape)\n",
    "\n",
    "for i in range(input_time_batched.shape[0]):\n",
    "\n",
    "    input_array[i] = input_time_batched[i, :, :History, :]\n",
    "\n",
    "    #print(input_array[i,0,-1,0])\n",
    "\n",
    "    target_2d = input_time_batched[i, :, History:, 0]\n",
    "    \n",
    "    target_array[i] = target_2d.reshape(\n",
    "        target_2d.shape[0], target_2d.shape[1], 1\n",
    "    )\n",
    "\n",
    "    #print(target_array[i,0,0,0])\n",
    "    #print()\n",
    "\n",
    "print(f\"X input shape is {input_array.shape}\")\n",
    "print(f\"y input shape is {target_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "tensor([[[-2.1741e-01,  1.4155e-01, -1.3005e-01,  1.9926e-01,  8.5210e-02,\n",
      "           1.8959e-01,  5.3461e-02, -1.1424e-02, -2.6726e-01,  2.0229e-01,\n",
      "           5.5080e-03, -8.5751e-02, -1.0218e-01,  1.2199e-01, -7.8119e-02,\n",
      "          -6.2057e-02,  1.9070e-01,  1.8517e-01, -1.6113e-01,  2.6615e-02,\n",
      "           4.9378e-02,  3.4724e-02, -1.1776e-01, -3.3504e-02, -9.9549e-02,\n",
      "           8.5244e-02, -9.6022e-02,  4.3169e-02,  2.4258e-02,  2.7842e-02,\n",
      "           1.1345e-01, -2.5625e-01, -1.2729e-01,  1.3911e-02,  7.2539e-02,\n",
      "          -1.2289e-01, -4.4210e-02,  9.2810e-02, -8.4308e-02, -1.3172e-01,\n",
      "           1.6895e-01, -1.1052e-01, -2.1750e-01,  2.5171e-01,  1.0761e-01,\n",
      "          -1.1721e-01, -3.0627e-01, -6.1632e-02],\n",
      "         [ 9.7127e-02, -4.6263e-02, -1.3138e-01, -4.4304e-02, -7.4628e-02,\n",
      "           1.4350e-01, -1.2894e-02,  3.2452e-02,  6.7748e-02,  7.1605e-02,\n",
      "          -2.3129e-01, -1.2900e-01, -4.0700e-02,  8.0614e-02, -1.9596e-01,\n",
      "           7.5757e-02, -5.8049e-02, -1.2471e-01,  1.1165e-01, -2.3549e-01,\n",
      "          -1.0285e-01, -1.3274e-01,  6.8181e-05,  3.6037e-02, -3.1989e-02,\n",
      "          -2.4049e-03, -3.8752e-02,  1.9758e-02,  2.2733e-01,  1.9487e-01,\n",
      "          -1.3810e-01, -2.9461e-02,  5.3205e-02, -1.5378e-01,  3.3993e-02,\n",
      "          -2.8012e-02,  2.8434e-03,  1.6525e-01, -1.3417e-02, -5.0065e-02,\n",
      "           1.2253e-01, -9.8498e-02, -6.0277e-02,  1.3442e-01,  6.5913e-02,\n",
      "           1.5311e-01, -1.0498e-01, -6.2532e-02],\n",
      "         [-1.3560e-01, -1.8572e-01, -1.2195e-01, -5.6240e-02, -9.7502e-02,\n",
      "          -1.7005e-01,  1.5743e-01, -8.6496e-02,  1.1610e-01, -1.8792e-02,\n",
      "           4.4914e-02,  1.3477e-01, -2.6112e-01, -7.8310e-02,  2.0036e-01,\n",
      "           8.1119e-02, -5.3912e-02, -1.2340e-01,  3.6602e-01,  7.4274e-02,\n",
      "           1.6543e-01,  1.4281e-01,  1.6092e-01, -4.4436e-02,  5.3909e-03,\n",
      "           2.4424e-01,  1.6025e-01, -2.3593e-01,  1.0565e-01,  1.7129e-01,\n",
      "           8.6642e-02,  3.1025e-02,  3.2091e-01,  5.7751e-02,  1.6577e-01,\n",
      "          -2.3305e-02,  1.1773e-01, -4.7129e-02,  7.8815e-02, -5.8153e-02,\n",
      "          -3.0365e-02, -3.4227e-02,  1.6266e-01, -2.4851e-01, -1.4412e-01,\n",
      "          -2.3209e-01,  2.5179e-01,  8.6504e-02]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.0629],\n",
      "         [-0.0696],\n",
      "         [-0.0410]],\n",
      "\n",
      "        [[-0.0551],\n",
      "         [-0.0607],\n",
      "         [-0.0419]],\n",
      "\n",
      "        [[-0.0505],\n",
      "         [-0.0540],\n",
      "         [-0.0434]],\n",
      "\n",
      "        [[-0.0479],\n",
      "         [-0.0496],\n",
      "         [-0.0440]],\n",
      "\n",
      "        [[-0.0465],\n",
      "         [-0.0471],\n",
      "         [-0.0441]],\n",
      "\n",
      "        [[-0.0457],\n",
      "         [-0.0457],\n",
      "         [-0.0442]],\n",
      "\n",
      "        [[-0.0452],\n",
      "         [-0.0450],\n",
      "         [-0.0442]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 0 is -4.7319231033325195\n",
      "tensor([[[-2.5336e-01,  7.1528e-02, -9.4136e-02,  2.1401e-01,  1.1204e-01,\n",
      "           2.3268e-01,  9.5639e-02, -2.9888e-02, -2.8770e-01,  2.4214e-01,\n",
      "          -2.4286e-02, -1.3534e-01, -1.1983e-01,  1.4077e-01, -5.8511e-02,\n",
      "          -8.5644e-02,  2.0707e-01,  2.4469e-01, -2.1612e-01,  1.8488e-02,\n",
      "           8.2125e-02,  8.9861e-02, -5.7172e-02, -5.8033e-02, -9.1117e-02,\n",
      "           6.3284e-02, -1.2889e-01,  7.6354e-02, -1.3639e-02, -5.9683e-03,\n",
      "           1.2449e-01, -2.2710e-01, -1.7465e-01,  2.1726e-02,  5.0977e-02,\n",
      "          -9.9473e-02, -6.4752e-02,  1.3644e-01, -8.0715e-02, -1.2719e-01,\n",
      "           1.2635e-01, -7.4678e-02, -2.3994e-01,  2.6642e-01,  6.7636e-02,\n",
      "          -7.3532e-02, -2.8337e-01, -2.6856e-02],\n",
      "         [ 3.4912e-02, -7.3706e-02, -9.1702e-02, -2.9814e-02, -8.8759e-02,\n",
      "           1.9981e-01,  4.3041e-02,  9.6417e-05,  3.2854e-02,  1.1443e-01,\n",
      "          -2.6087e-01, -1.7988e-01, -6.1991e-02,  9.1763e-02, -1.7468e-01,\n",
      "           5.1358e-02, -2.0084e-02, -8.8821e-02,  1.0623e-01, -2.6108e-01,\n",
      "          -1.0399e-01, -9.4524e-02,  8.5993e-02,  2.4711e-02, -1.2771e-02,\n",
      "          -1.9518e-02, -8.3128e-02,  6.4318e-02,  1.9778e-01,  1.8635e-01,\n",
      "          -1.1616e-01,  3.8146e-02, -2.0655e-03, -1.5646e-01,  1.5886e-03,\n",
      "          -2.6405e-02, -1.9268e-02,  2.2192e-01, -2.2412e-02, -5.8949e-02,\n",
      "           7.1178e-02, -8.1068e-02, -9.5622e-02,  1.5079e-01,  2.9815e-02,\n",
      "           1.6973e-01, -7.8554e-02, -4.0460e-02],\n",
      "         [-1.5580e-01, -2.0004e-01, -7.9015e-02, -3.2257e-02, -1.1695e-01,\n",
      "          -1.5047e-01,  2.0321e-01, -1.2346e-01,  9.4281e-02,  1.4428e-02,\n",
      "           2.0256e-03,  8.5515e-02, -3.0252e-01, -4.4489e-02,  1.8668e-01,\n",
      "           5.0179e-02, -1.9529e-02, -6.2581e-02,  4.0169e-01,  7.8137e-02,\n",
      "           1.8838e-01,  1.8133e-01,  1.9726e-01, -5.9145e-02,  2.1620e-02,\n",
      "           2.2621e-01,  1.0016e-01, -1.9634e-01,  5.6537e-02,  1.6500e-01,\n",
      "           1.1309e-01,  1.2109e-01,  2.9561e-01,  5.9079e-02,  1.3414e-01,\n",
      "          -2.3988e-02,  1.0089e-01, -2.0886e-02,  6.7319e-02, -7.1964e-02,\n",
      "          -7.0095e-02,  1.3136e-03,  1.1304e-01, -1.5916e-01, -1.6537e-01,\n",
      "          -2.1016e-01,  2.6187e-01,  1.1413e-01]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.0116],\n",
      "         [-0.0337],\n",
      "         [-0.0061]],\n",
      "\n",
      "        [[-0.0113],\n",
      "         [-0.0247],\n",
      "         [-0.0071]],\n",
      "\n",
      "        [[-0.0104],\n",
      "         [-0.0187],\n",
      "         [-0.0088]],\n",
      "\n",
      "        [[-0.0098],\n",
      "         [-0.0145],\n",
      "         [-0.0091]],\n",
      "\n",
      "        [[-0.0095],\n",
      "         [-0.0119],\n",
      "         [-0.0090]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [-0.0103],\n",
      "         [-0.0089]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [-0.0095],\n",
      "         [-0.0087]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 1 is -4.795817136764526\n",
      "tensor([[[-0.2697,  0.0380, -0.0630,  0.2142,  0.1249,  0.2485,  0.1013,\n",
      "          -0.0389, -0.2854,  0.2719, -0.0346, -0.1616, -0.1283,  0.1635,\n",
      "          -0.0449, -0.1049,  0.2209,  0.2661, -0.2420,  0.0075,  0.1023,\n",
      "           0.1199, -0.0303, -0.0722, -0.0842,  0.0507, -0.1395,  0.0893,\n",
      "          -0.0346, -0.0236,  0.1327, -0.2177, -0.2023,  0.0239,  0.0423,\n",
      "          -0.0923, -0.0858,  0.1541, -0.0786, -0.1295,  0.1102, -0.0510,\n",
      "          -0.2489,  0.2862,  0.0477, -0.0468, -0.2763, -0.0117],\n",
      "         [ 0.0094, -0.0905, -0.0631, -0.0209, -0.0900,  0.2280,  0.0655,\n",
      "          -0.0158,  0.0088,  0.1383, -0.2878, -0.2058, -0.0848,  0.1029,\n",
      "          -0.1679,  0.0363, -0.0029, -0.0599,  0.1054, -0.2663, -0.1068,\n",
      "          -0.0735,  0.1462,  0.0201,  0.0043, -0.0295, -0.1049,  0.0858,\n",
      "           0.1739,  0.1851, -0.1155,  0.0838, -0.0442, -0.1687, -0.0178,\n",
      "          -0.0263, -0.0337,  0.2484, -0.0265, -0.0676,  0.0417, -0.0689,\n",
      "          -0.1107,  0.1629,  0.0147,  0.1861, -0.0633, -0.0318],\n",
      "         [-0.1659, -0.2110, -0.0442, -0.0121, -0.1183, -0.1350,  0.2145,\n",
      "          -0.1450,  0.0749,  0.0310, -0.0171,  0.0528, -0.3195, -0.0257,\n",
      "           0.1842,  0.0344, -0.0044, -0.0064,  0.4067,  0.0745,  0.1981,\n",
      "           0.1990,  0.2155, -0.0643,  0.0357,  0.2147,  0.0710, -0.1724,\n",
      "           0.0239,  0.1652,  0.1284,  0.1687,  0.2746,  0.0583,  0.1167,\n",
      "          -0.0271,  0.0901, -0.0071,  0.0614, -0.0871, -0.0937,  0.0183,\n",
      "           0.0788, -0.1032, -0.1782, -0.2006,  0.2672,  0.1181]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[ 0.0297],\n",
      "         [-0.0021],\n",
      "         [ 0.0254]],\n",
      "\n",
      "        [[ 0.0292],\n",
      "         [ 0.0078],\n",
      "         [ 0.0257]],\n",
      "\n",
      "        [[ 0.0285],\n",
      "         [ 0.0154],\n",
      "         [ 0.0254]],\n",
      "\n",
      "        [[ 0.0280],\n",
      "         [ 0.0207],\n",
      "         [ 0.0259]],\n",
      "\n",
      "        [[ 0.0277],\n",
      "         [ 0.0238],\n",
      "         [ 0.0265]],\n",
      "\n",
      "        [[ 0.0276],\n",
      "         [ 0.0255],\n",
      "         [ 0.0269]],\n",
      "\n",
      "        [[ 0.0275],\n",
      "         [ 0.0263],\n",
      "         [ 0.0271]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 2 is -3.2603865464528403\n",
      "tensor([[[-0.2266,  0.1100, -0.0824,  0.1773,  0.0946,  0.1813,  0.0346,\n",
      "          -0.0065, -0.2438,  0.2663,  0.0078, -0.1213, -0.0963,  0.1761,\n",
      "          -0.0469, -0.0954,  0.2167,  0.1774, -0.1844,  0.0041,  0.0809,\n",
      "           0.0705, -0.1013, -0.0579, -0.0989,  0.0740, -0.0862,  0.0411,\n",
      "           0.0033,  0.0085,  0.1259, -0.2672, -0.1433,  0.0238,  0.0807,\n",
      "          -0.1100, -0.0791,  0.1063, -0.0834, -0.1376,  0.1712, -0.0843,\n",
      "          -0.2363,  0.2931,  0.0839, -0.0790, -0.3238, -0.0460],\n",
      "         [ 0.0754, -0.0599, -0.1101, -0.0295, -0.0668,  0.1655,  0.0016,\n",
      "           0.0344,  0.0437,  0.0915, -0.2785, -0.1518, -0.0712,  0.0985,\n",
      "          -0.1986,  0.0644, -0.0490, -0.0961,  0.1134, -0.2315, -0.1096,\n",
      "          -0.1232,  0.0953,  0.0368, -0.0073, -0.0056, -0.0675,  0.0372,\n",
      "           0.2047,  0.2088, -0.1492,  0.0311,  0.0081, -0.1842,  0.0124,\n",
      "          -0.0296, -0.0184,  0.1768, -0.0252, -0.0670,  0.0957, -0.0932,\n",
      "          -0.0655,  0.1552,  0.0646,  0.1811, -0.0866, -0.0631],\n",
      "         [-0.1476, -0.1944, -0.0966, -0.0204, -0.0854, -0.1529,  0.1523,\n",
      "          -0.1055,  0.0919, -0.0045,  0.0256,  0.1052, -0.2722, -0.0688,\n",
      "           0.2023,  0.0741, -0.0441, -0.0635,  0.3451,  0.0691,  0.1659,\n",
      "           0.1482,  0.1813, -0.0458,  0.0252,  0.2407,  0.1297, -0.2100,\n",
      "           0.0745,  0.1784,  0.1044,  0.0782,  0.3072,  0.0509,  0.1491,\n",
      "          -0.0286,  0.1033, -0.0400,  0.0733, -0.0923, -0.0510, -0.0378,\n",
      "           0.1220, -0.1767, -0.1510, -0.2290,  0.2576,  0.0702]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.0517],\n",
      "         [0.0191],\n",
      "         [0.0510]],\n",
      "\n",
      "        [[0.0576],\n",
      "         [0.0339],\n",
      "         [0.0525]],\n",
      "\n",
      "        [[0.0603],\n",
      "         [0.0447],\n",
      "         [0.0550]],\n",
      "\n",
      "        [[0.0610],\n",
      "         [0.0515],\n",
      "         [0.0568]],\n",
      "\n",
      "        [[0.0610],\n",
      "         [0.0554],\n",
      "         [0.0580]],\n",
      "\n",
      "        [[0.0608],\n",
      "         [0.0577],\n",
      "         [0.0589]],\n",
      "\n",
      "        [[0.0605],\n",
      "         [0.0588],\n",
      "         [0.0594]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 3 is -2.086433192094167\n",
      "tensor([[[-0.2156,  0.1267, -0.0925,  0.1687,  0.0985,  0.1717,  0.0207,\n",
      "          -0.0028, -0.2498,  0.2603,  0.0172, -0.1173, -0.0853,  0.1675,\n",
      "          -0.0388, -0.0925,  0.2111,  0.1636, -0.1922,  0.0033,  0.0870,\n",
      "           0.0638, -0.1235, -0.0604, -0.1112,  0.0822, -0.0638,  0.0249,\n",
      "           0.0099,  0.0102,  0.1252, -0.2774, -0.1200,  0.0374,  0.0911,\n",
      "          -0.1022, -0.0793,  0.1081, -0.0847, -0.1300,  0.1822, -0.0983,\n",
      "          -0.2475,  0.2838,  0.0845, -0.0867, -0.3463, -0.0490],\n",
      "         [ 0.0875, -0.0395, -0.1415, -0.0303, -0.0704,  0.1547, -0.0124,\n",
      "           0.0464,  0.0547,  0.0636, -0.2661, -0.1349, -0.0657,  0.0850,\n",
      "          -0.2050,  0.0753, -0.0661, -0.1130,  0.1219, -0.2400, -0.1138,\n",
      "          -0.1380,  0.0741,  0.0439, -0.0134,  0.0049, -0.0519,  0.0259,\n",
      "           0.2364,  0.2212, -0.1445,  0.0107,  0.0304, -0.1810,  0.0215,\n",
      "          -0.0283, -0.0104,  0.1618, -0.0309, -0.0649,  0.1052, -0.1032,\n",
      "          -0.0531,  0.1412,  0.0761,  0.1693, -0.0908, -0.0717],\n",
      "         [-0.1395, -0.1784, -0.1296, -0.0204, -0.0877, -0.1600,  0.1533,\n",
      "          -0.0992,  0.0997, -0.0205,  0.0333,  0.1307, -0.2755, -0.0894,\n",
      "           0.2010,  0.0823, -0.0536, -0.0886,  0.3539,  0.0780,  0.1560,\n",
      "           0.1368,  0.1736, -0.0418,  0.0191,  0.2451,  0.1437, -0.2187,\n",
      "           0.0970,  0.1824,  0.0967,  0.0497,  0.3194,  0.0474,  0.1562,\n",
      "          -0.0262,  0.1095, -0.0489,  0.0754, -0.0866, -0.0364, -0.0594,\n",
      "           0.1416, -0.1991, -0.1408, -0.2314,  0.2544,  0.0622]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.0941],\n",
      "         [0.0480],\n",
      "         [0.0807]],\n",
      "\n",
      "        [[0.0964],\n",
      "         [0.0652],\n",
      "         [0.0845]],\n",
      "\n",
      "        [[0.0972],\n",
      "         [0.0769],\n",
      "         [0.0874]],\n",
      "\n",
      "        [[0.0967],\n",
      "         [0.0843],\n",
      "         [0.0895]],\n",
      "\n",
      "        [[0.0959],\n",
      "         [0.0886],\n",
      "         [0.0911]],\n",
      "\n",
      "        [[0.0952],\n",
      "         [0.0910],\n",
      "         [0.0922]],\n",
      "\n",
      "        [[0.0947],\n",
      "         [0.0923],\n",
      "         [0.0928]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 4 is -1.4623843709627788\n",
      "tensor([[[-1.9539e-01,  1.6552e-01, -1.0001e-01,  1.5397e-01,  9.3449e-02,\n",
      "           1.5005e-01,  3.0910e-03,  7.4419e-03, -2.3840e-01,  2.5439e-01,\n",
      "           3.2785e-02, -1.0178e-01, -6.7717e-02,  1.6317e-01, -3.3683e-02,\n",
      "          -8.5082e-02,  2.0394e-01,  1.2902e-01, -1.8263e-01,  2.8638e-03,\n",
      "           8.8443e-02,  4.6652e-02, -1.4900e-01, -6.1545e-02, -1.2534e-01,\n",
      "           9.8192e-02, -3.3353e-02, -4.8392e-05,  1.8974e-02,  1.5455e-02,\n",
      "           1.2843e-01, -2.9549e-01, -8.6830e-02,  4.9634e-02,  1.1109e-01,\n",
      "          -1.0120e-01, -7.6252e-02,  9.9543e-02, -8.7862e-02, -1.2511e-01,\n",
      "           1.9968e-01, -1.1265e-01, -2.4986e-01,  2.7372e-01,  9.4966e-02,\n",
      "          -1.0587e-01, -3.7401e-01, -5.7675e-02],\n",
      "         [ 1.1012e-01, -1.2452e-02, -1.7068e-01, -3.3481e-02, -6.8312e-02,\n",
      "           1.2365e-01, -2.5902e-02,  6.8415e-02,  6.8418e-02,  2.8324e-02,\n",
      "          -2.5855e-01, -1.0305e-01, -5.3774e-02,  7.1784e-02, -2.1752e-01,\n",
      "           9.1300e-02, -9.6593e-02, -1.2812e-01,  1.2239e-01, -2.3243e-01,\n",
      "          -1.1697e-01, -1.6011e-01,  3.8257e-02,  5.2053e-02, -2.2132e-02,\n",
      "           2.2931e-02, -2.9798e-02,  4.7930e-03,  2.5347e-01,  2.3233e-01,\n",
      "          -1.5056e-01, -2.0442e-02,  6.5379e-02, -1.7753e-01,  4.2971e-02,\n",
      "          -2.6050e-02,  5.1822e-03,  1.3549e-01, -3.4507e-02, -5.9783e-02,\n",
      "           1.1825e-01, -1.1179e-01, -2.3340e-02,  1.2125e-01,  9.8409e-02,\n",
      "           1.5854e-01, -9.8658e-02, -8.1375e-02],\n",
      "         [-1.2400e-01, -1.5880e-01, -1.6126e-01, -2.3860e-02, -8.0931e-02,\n",
      "          -1.6519e-01,  1.3685e-01, -8.6133e-02,  1.0673e-01, -4.1924e-02,\n",
      "           4.8012e-02,  1.5916e-01, -2.6251e-01, -1.2537e-01,  2.0756e-01,\n",
      "           9.7169e-02, -7.1243e-02, -1.1880e-01,  3.3697e-01,  8.2361e-02,\n",
      "           1.3520e-01,  1.1431e-01,  1.5554e-01, -3.5074e-02,  8.8601e-03,\n",
      "           2.5739e-01,  1.6853e-01, -2.3819e-01,  1.2093e-01,  1.8799e-01,\n",
      "           8.8703e-02,  9.5840e-03,  3.3116e-01,  4.7697e-02,  1.6990e-01,\n",
      "          -2.6334e-02,  1.2176e-01, -6.2297e-02,  8.0341e-02, -7.4907e-02,\n",
      "          -1.6185e-02, -8.2947e-02,  1.6736e-01, -2.4181e-01, -1.2849e-01,\n",
      "          -2.3897e-01,  2.4955e-01,  4.9171e-02]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[0.1324],\n",
      "         [0.0769],\n",
      "         [0.1102]],\n",
      "\n",
      "        [[0.1349],\n",
      "         [0.0966],\n",
      "         [0.1161]],\n",
      "\n",
      "        [[0.1351],\n",
      "         [0.1105],\n",
      "         [0.1208]],\n",
      "\n",
      "        [[0.1339],\n",
      "         [0.1189],\n",
      "         [0.1239]],\n",
      "\n",
      "        [[0.1327],\n",
      "         [0.1237],\n",
      "         [0.1261]],\n",
      "\n",
      "        [[0.1317],\n",
      "         [0.1265],\n",
      "         [0.1275]],\n",
      "\n",
      "        [[0.1310],\n",
      "         [0.1280],\n",
      "         [0.1284]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 5 is -1.1397867447800107\n",
      "tensor([[[-0.1941,  0.1782, -0.1007,  0.1459,  0.0964,  0.1451, -0.0035,\n",
      "           0.0078, -0.2362,  0.2602,  0.0376, -0.1013, -0.0595,  0.1677,\n",
      "          -0.0252, -0.0868,  0.2046,  0.1160, -0.1884,  0.0017,  0.0982,\n",
      "           0.0477, -0.1585, -0.0694, -0.1346,  0.1066, -0.0189, -0.0108,\n",
      "           0.0194,  0.0112,  0.1334, -0.3035, -0.0744,  0.0601,  0.1208,\n",
      "          -0.0945, -0.0829,  0.1054, -0.0890, -0.1225,  0.2051, -0.1188,\n",
      "          -0.2600,  0.2744,  0.0940, -0.1152, -0.3905, -0.0598],\n",
      "         [ 0.1154, -0.0012, -0.1894, -0.0330, -0.0701,  0.1108, -0.0273,\n",
      "           0.0764,  0.0715,  0.0124, -0.2611, -0.0893, -0.0504,  0.0652,\n",
      "          -0.2238,  0.0971, -0.1098, -0.1338,  0.1242, -0.2321, -0.1204,\n",
      "          -0.1682,  0.0287,  0.0566, -0.0240,  0.0306, -0.0240, -0.0005,\n",
      "           0.2673,  0.2405, -0.1500, -0.0272,  0.0775, -0.1767,  0.0489,\n",
      "          -0.0241,  0.0145,  0.1302, -0.0396, -0.0586,  0.1183, -0.1167,\n",
      "          -0.0099,  0.1118,  0.1070,  0.1558, -0.0988, -0.0835],\n",
      "         [-0.1172, -0.1506, -0.1778, -0.0205, -0.0796, -0.1663,  0.1323,\n",
      "          -0.0847,  0.1082, -0.0493,  0.0501,  0.1716, -0.2603, -0.1416,\n",
      "           0.2096,  0.1008, -0.0751, -0.1286,  0.3333,  0.0861,  0.1263,\n",
      "           0.1080,  0.1479, -0.0324,  0.0047,  0.2591,  0.1741, -0.2438,\n",
      "           0.1318,  0.1911,  0.0890, -0.0013,  0.3343,  0.0483,  0.1724,\n",
      "          -0.0278,  0.1274, -0.0668,  0.0812, -0.0687, -0.0097, -0.0936,\n",
      "           0.1757, -0.2551, -0.1257, -0.2388,  0.2477,  0.0453]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.1759],\n",
      "         [0.1089],\n",
      "         [0.1422]],\n",
      "\n",
      "        [[0.1768],\n",
      "         [0.1307],\n",
      "         [0.1507]],\n",
      "\n",
      "        [[0.1754],\n",
      "         [0.1462],\n",
      "         [0.1568]],\n",
      "\n",
      "        [[0.1730],\n",
      "         [0.1558],\n",
      "         [0.1607]],\n",
      "\n",
      "        [[0.1711],\n",
      "         [0.1611],\n",
      "         [0.1633]],\n",
      "\n",
      "        [[0.1699],\n",
      "         [0.1640],\n",
      "         [0.1649]],\n",
      "\n",
      "        [[0.1690],\n",
      "         [0.1656],\n",
      "         [0.1660]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 6 is -0.9530850854184892\n",
      "tensor([[[-0.2115,  0.1601, -0.0961,  0.1472,  0.1098,  0.1604,  0.0028,\n",
      "          -0.0023, -0.2446,  0.2772,  0.0300, -0.1161, -0.0575,  0.1778,\n",
      "          -0.0140, -0.0974,  0.2143,  0.1281, -0.2141, -0.0010,  0.1181,\n",
      "           0.0698, -0.1510, -0.0847, -0.1405,  0.1069, -0.0256, -0.0052,\n",
      "           0.0108, -0.0035,  0.1421, -0.3031, -0.0858,  0.0710,  0.1172,\n",
      "          -0.0837, -0.0973,  0.1279, -0.0873, -0.1203,  0.1966, -0.1190,\n",
      "          -0.2776,  0.2858,  0.0797, -0.1120, -0.3972, -0.0538],\n",
      "         [ 0.0999, -0.0099, -0.2027, -0.0281, -0.0782,  0.1163, -0.0119,\n",
      "           0.0681,  0.0622,  0.0170, -0.2740, -0.0920, -0.0515,  0.0660,\n",
      "          -0.2215,  0.0919, -0.1056, -0.1319,  0.1270, -0.2418, -0.1252,\n",
      "          -0.1622,  0.0436,  0.0567, -0.0205,  0.0292, -0.0372,  0.0136,\n",
      "           0.2816,  0.2447, -0.1413, -0.0108,  0.0695, -0.1759,  0.0410,\n",
      "          -0.0225,  0.0177,  0.1503, -0.0459, -0.0609,  0.1026, -0.1168,\n",
      "          -0.0133,  0.1148,  0.1001,  0.1592, -0.0908, -0.0762],\n",
      "         [-0.1200, -0.1576, -0.1867, -0.0112, -0.0857, -0.1638,  0.1435,\n",
      "          -0.1008,  0.1040, -0.0412,  0.0369,  0.1724, -0.2715, -0.1380,\n",
      "           0.2055,  0.0913, -0.0644, -0.1242,  0.3449,  0.0911,  0.1268,\n",
      "           0.1199,  0.1525, -0.0353,  0.0057,  0.2520,  0.1571, -0.2362,\n",
      "           0.1325,  0.1913,  0.0986,  0.0203,  0.3298,  0.0504,  0.1626,\n",
      "          -0.0300,  0.1273, -0.0609,  0.0777, -0.0672, -0.0180, -0.0900,\n",
      "           0.1681, -0.2411, -0.1332, -0.2312,  0.2492,  0.0550]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.2232],\n",
      "         [0.1434],\n",
      "         [0.1766]],\n",
      "\n",
      "        [[0.2201],\n",
      "         [0.1676],\n",
      "         [0.1876]],\n",
      "\n",
      "        [[0.2169],\n",
      "         [0.1841],\n",
      "         [0.1942]],\n",
      "\n",
      "        [[0.2135],\n",
      "         [0.1937],\n",
      "         [0.1986]],\n",
      "\n",
      "        [[0.2109],\n",
      "         [0.1994],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.2092],\n",
      "         [0.2026],\n",
      "         [0.2036]],\n",
      "\n",
      "        [[0.2082],\n",
      "         [0.2044],\n",
      "         [0.2048]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 7 is -0.8291759069595072\n",
      "tensor([[[-0.2598,  0.0925, -0.0692,  0.1610,  0.1428,  0.2079,  0.0382,\n",
      "          -0.0249, -0.2645,  0.3111, -0.0012, -0.1597, -0.0763,  0.1951,\n",
      "          -0.0011, -0.1201,  0.2307,  0.1799, -0.2713, -0.0062,  0.1591,\n",
      "           0.1207, -0.0925, -0.1166, -0.1346,  0.0952, -0.0617,  0.0288,\n",
      "          -0.0274, -0.0421,  0.1528, -0.2832, -0.1344,  0.0782,  0.0931,\n",
      "          -0.0652, -0.1288,  0.1742, -0.0811, -0.1228,  0.1555, -0.0923,\n",
      "          -0.2996,  0.3048,  0.0473, -0.0843, -0.3791, -0.0310],\n",
      "         [ 0.0465, -0.0429, -0.1828, -0.0084, -0.0925,  0.1622,  0.0362,\n",
      "           0.0321,  0.0282,  0.0613, -0.2971, -0.1392, -0.0680,  0.0763,\n",
      "          -0.2041,  0.0678, -0.0677, -0.1002,  0.1280, -0.2696, -0.1285,\n",
      "          -0.1291,  0.1156,  0.0517, -0.0026,  0.0078, -0.0840,  0.0597,\n",
      "           0.2772,  0.2443, -0.1168,  0.0515,  0.0142, -0.1775,  0.0051,\n",
      "          -0.0249,  0.0050,  0.2002, -0.0542, -0.0646,  0.0571, -0.1044,\n",
      "          -0.0495,  0.1363,  0.0642,  0.1789, -0.0673, -0.0506],\n",
      "         [-0.1385, -0.1798, -0.1583,  0.0138, -0.1026, -0.1474,  0.1831,\n",
      "          -0.1370,  0.0842, -0.0068, -0.0008,  0.1325, -0.3078, -0.0990,\n",
      "           0.1920,  0.0628, -0.0321, -0.0701,  0.3783,  0.0955,  0.1462,\n",
      "           0.1560,  0.1840, -0.0477,  0.0202,  0.2279,  0.0992, -0.1990,\n",
      "           0.0946,  0.1852,  0.1208,  0.1013,  0.3049,  0.0524,  0.1330,\n",
      "          -0.0327,  0.1134, -0.0372,  0.0670, -0.0770, -0.0551, -0.0544,\n",
      "           0.1258, -0.1708, -0.1557, -0.2070,  0.2584,  0.0824]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.2710],\n",
      "         [0.1800],\n",
      "         [0.2129]],\n",
      "\n",
      "        [[0.2656],\n",
      "         [0.2063],\n",
      "         [0.2262]],\n",
      "\n",
      "        [[0.2598],\n",
      "         [0.2221],\n",
      "         [0.2325]],\n",
      "\n",
      "        [[0.2547],\n",
      "         [0.2319],\n",
      "         [0.2371]],\n",
      "\n",
      "        [[0.2510],\n",
      "         [0.2377],\n",
      "         [0.2400]],\n",
      "\n",
      "        [[0.2487],\n",
      "         [0.2409],\n",
      "         [0.2420]],\n",
      "\n",
      "        [[0.2473],\n",
      "         [0.2428],\n",
      "         [0.2432]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 8 is -0.7395317772564328\n",
      "tensor([[[-0.2781,  0.0794, -0.0497,  0.1576,  0.1538,  0.2205,  0.0326,\n",
      "          -0.0327, -0.2571,  0.3427, -0.0013, -0.1763, -0.0792,  0.2250,\n",
      "           0.0110, -0.1411,  0.2507,  0.1866, -0.2866, -0.0100,  0.1759,\n",
      "           0.1430, -0.0829, -0.1330, -0.1345,  0.0927, -0.0651,  0.0333,\n",
      "          -0.0356, -0.0536,  0.1644, -0.2905, -0.1561,  0.0858,  0.0911,\n",
      "          -0.0629, -0.1557,  0.1843, -0.0787, -0.1284,  0.1572, -0.0852,\n",
      "          -0.3093,  0.3363,  0.0360, -0.0792, -0.3854, -0.0293],\n",
      "         [ 0.0387, -0.0570, -0.1751, -0.0044, -0.0904,  0.1690,  0.0470,\n",
      "           0.0253,  0.0127,  0.0743, -0.3262, -0.1506, -0.0879,  0.0850,\n",
      "          -0.2039,  0.0586, -0.0619, -0.0836,  0.1315, -0.2677, -0.1355,\n",
      "          -0.1183,  0.1587,  0.0503,  0.0135,  0.0008, -0.1001,  0.0746,\n",
      "           0.2656,  0.2489, -0.1232,  0.0882, -0.0142, -0.1917, -0.0098,\n",
      "          -0.0232,  0.0024,  0.2149, -0.0584, -0.0735,  0.0423, -0.0975,\n",
      "          -0.0562,  0.1462,  0.0610,  0.1973, -0.0568, -0.0445],\n",
      "         [-0.1444, -0.1932, -0.1367,  0.0264, -0.0977, -0.1391,  0.1780,\n",
      "          -0.1498,  0.0720,  0.0033, -0.0101,  0.1127, -0.3108, -0.0861,\n",
      "           0.1930,  0.0549, -0.0244, -0.0332,  0.3717,  0.0895,  0.1488,\n",
      "           0.1651,  0.1927, -0.0496,  0.0308,  0.2177,  0.0819, -0.1862,\n",
      "           0.0777,  0.1865,  0.1290,  0.1308,  0.2921,  0.0525,  0.1236,\n",
      "          -0.0383,  0.1074, -0.0300,  0.0637, -0.0894, -0.0675, -0.0413,\n",
      "           0.1050, -0.1429, -0.1649, -0.2006,  0.2623,  0.0836]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.3175],\n",
      "         [0.2151],\n",
      "         [0.2497]],\n",
      "\n",
      "        [[0.3095],\n",
      "         [0.2428],\n",
      "         [0.2638]],\n",
      "\n",
      "        [[0.3027],\n",
      "         [0.2602],\n",
      "         [0.2716]],\n",
      "\n",
      "        [[0.2967],\n",
      "         [0.2711],\n",
      "         [0.2769]],\n",
      "\n",
      "        [[0.2927],\n",
      "         [0.2775],\n",
      "         [0.2804]],\n",
      "\n",
      "        [[0.2902],\n",
      "         [0.2813],\n",
      "         [0.2827]],\n",
      "\n",
      "        [[0.2887],\n",
      "         [0.2835],\n",
      "         [0.2840]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 9 is -0.6594625733250086\n",
      "tensor([[[-0.2721,  0.1175, -0.0545,  0.1398,  0.1450,  0.1971,  0.0024,\n",
      "          -0.0200, -0.2418,  0.3560,  0.0201, -0.1686, -0.0663,  0.2437,\n",
      "           0.0210, -0.1475,  0.2587,  0.1485, -0.2708, -0.0072,  0.1740,\n",
      "           0.1315, -0.1172, -0.1359, -0.1463,  0.1055, -0.0364,  0.0092,\n",
      "          -0.0202, -0.0422,  0.1685, -0.3122, -0.1323,  0.0951,  0.1120,\n",
      "          -0.0647, -0.1684,  0.1705, -0.0774, -0.1338,  0.1904, -0.1084,\n",
      "          -0.3162,  0.3543,  0.0461, -0.1022, -0.4121, -0.0499],\n",
      "         [ 0.0689, -0.0403, -0.1961, -0.0073, -0.0808,  0.1405,  0.0195,\n",
      "           0.0495,  0.0277,  0.0462, -0.3321, -0.1270, -0.0885,  0.0793,\n",
      "          -0.2213,  0.0714, -0.0846, -0.0980,  0.1377, -0.2562, -0.1395,\n",
      "          -0.1396,  0.1503,  0.0589,  0.0130,  0.0089, -0.0883,  0.0552,\n",
      "           0.2767,  0.2651, -0.1364,  0.0779,  0.0030, -0.2031, -0.0039,\n",
      "          -0.0222,  0.0168,  0.1852, -0.0631, -0.0756,  0.0649, -0.1085,\n",
      "          -0.0324,  0.1387,  0.0862,  0.2025, -0.0638, -0.0572],\n",
      "         [-0.1364, -0.1864, -0.1545,  0.0227, -0.0853, -0.1490,  0.1514,\n",
      "          -0.1296,  0.0794, -0.0133,  0.0053,  0.1325, -0.2922, -0.1031,\n",
      "           0.1984,  0.0718, -0.0402, -0.0526,  0.3473,  0.0869,  0.1363,\n",
      "           0.1445,  0.1779, -0.0426,  0.0290,  0.2262,  0.1061, -0.2009,\n",
      "           0.0948,  0.1917,  0.1169,  0.0966,  0.3069,  0.0479,  0.1365,\n",
      "          -0.0406,  0.1135, -0.0431,  0.0683, -0.0940, -0.0494, -0.0593,\n",
      "           0.1214, -0.1738, -0.1514, -0.2094,  0.2578,  0.0641]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.3638],\n",
      "         [0.2453],\n",
      "         [0.2844]],\n",
      "\n",
      "        [[0.3540],\n",
      "         [0.2759],\n",
      "         [0.2989]],\n",
      "\n",
      "        [[0.3453],\n",
      "         [0.2962],\n",
      "         [0.3084]],\n",
      "\n",
      "        [[0.3383],\n",
      "         [0.3091],\n",
      "         [0.3147]],\n",
      "\n",
      "        [[0.3337],\n",
      "         [0.3167],\n",
      "         [0.3188]],\n",
      "\n",
      "        [[0.3307],\n",
      "         [0.3205],\n",
      "         [0.3214]],\n",
      "\n",
      "        [[0.3287],\n",
      "         [0.3227],\n",
      "         [0.3230]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 10 is -0.5943913570132554\n",
      "tensor([[[-2.6002e-01,  1.6877e-01, -6.2514e-02,  1.2403e-01,  1.3851e-01,\n",
      "           1.7233e-01, -2.2964e-02, -2.2733e-03, -2.3274e-01,  3.5835e-01,\n",
      "           4.0628e-02, -1.6058e-01, -5.0347e-02,  2.4732e-01,  3.2709e-02,\n",
      "          -1.4660e-01,  2.5901e-01,  1.1096e-01, -2.6069e-01, -2.6097e-03,\n",
      "           1.7283e-01,  1.1354e-01, -1.5313e-01, -1.3792e-01, -1.6344e-01,\n",
      "           1.2066e-01, -5.5488e-03, -1.8449e-02, -6.7192e-03, -2.9944e-02,\n",
      "           1.7059e-01, -3.2999e-01, -9.6703e-02,  1.0855e-01,  1.3525e-01,\n",
      "          -6.5606e-02, -1.7580e-01,  1.5739e-01, -7.5115e-02, -1.3375e-01,\n",
      "           2.1855e-01, -1.3896e-01, -3.2580e-01,  3.5781e-01,  5.7818e-02,\n",
      "          -1.2948e-01, -4.4184e-01, -7.2088e-02],\n",
      "         [ 1.0004e-01, -1.1664e-02, -2.2474e-01, -9.6500e-03, -7.6089e-02,\n",
      "           1.0801e-01, -3.6042e-03,  7.9085e-02,  4.7824e-02,  5.9722e-03,\n",
      "          -3.2630e-01, -9.6546e-02, -8.1703e-02,  6.3406e-02, -2.3956e-01,\n",
      "           9.0501e-02, -1.1329e-01, -1.1677e-01,  1.4273e-01, -2.5076e-01,\n",
      "          -1.4284e-01, -1.6556e-01,  1.2528e-01,  6.9913e-02,  7.0620e-03,\n",
      "           2.2492e-02, -6.8427e-02,  3.1529e-02,  2.9629e-01,  2.8139e-01,\n",
      "          -1.4461e-01,  5.1355e-02,  3.4855e-02, -2.0625e-01,  8.9807e-03,\n",
      "          -1.9675e-02,  3.6996e-02,  1.4856e-01, -6.9354e-02, -7.2734e-02,\n",
      "           8.6543e-02, -1.1992e-01, -2.3804e-04,  1.1684e-01,  1.1492e-01,\n",
      "           1.9868e-01, -7.2553e-02, -7.0120e-02],\n",
      "         [-1.2300e-01, -1.6882e-01, -1.8203e-01,  1.6111e-02, -7.8097e-02,\n",
      "          -1.6010e-01,  1.3241e-01, -1.0450e-01,  9.0783e-02, -3.6172e-02,\n",
      "           2.2412e-02,  1.6036e-01, -2.7792e-01, -1.3135e-01,  2.0131e-01,\n",
      "           9.1506e-02, -5.9965e-02, -8.4759e-02,  3.3014e-01,  8.9438e-02,\n",
      "           1.2015e-01,  1.1823e-01,  1.6041e-01, -3.5593e-02,  2.1751e-02,\n",
      "           2.4024e-01,  1.3636e-01, -2.1986e-01,  1.1639e-01,  1.9603e-01,\n",
      "           9.9524e-02,  5.0718e-02,  3.2449e-01,  4.3044e-02,  1.5286e-01,\n",
      "          -4.0277e-02,  1.2408e-01, -5.8561e-02,  7.3487e-02, -8.9231e-02,\n",
      "          -2.7134e-02, -7.9512e-02,  1.4784e-01, -2.2001e-01, -1.3172e-01,\n",
      "          -2.1730e-01,  2.5178e-01,  4.7240e-02]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[0.4118],\n",
      "         [0.2750],\n",
      "         [0.3185]],\n",
      "\n",
      "        [[0.3994],\n",
      "         [0.3082],\n",
      "         [0.3339]],\n",
      "\n",
      "        [[0.3892],\n",
      "         [0.3313],\n",
      "         [0.3443]],\n",
      "\n",
      "        [[0.3812],\n",
      "         [0.3459],\n",
      "         [0.3513]],\n",
      "\n",
      "        [[0.3755],\n",
      "         [0.3538],\n",
      "         [0.3561]],\n",
      "\n",
      "        [[0.3715],\n",
      "         [0.3583],\n",
      "         [0.3593]],\n",
      "\n",
      "        [[0.3688],\n",
      "         [0.3609],\n",
      "         [0.3613]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 11 is -0.5373609472570047\n",
      "tensor([[[-2.6057e-01,  1.9323e-01, -6.5222e-02,  1.1681e-01,  1.4454e-01,\n",
      "           1.6791e-01, -3.4829e-02,  4.8272e-03, -2.3600e-01,  3.6446e-01,\n",
      "           4.6678e-02, -1.6398e-01, -3.9676e-02,  2.4799e-01,  4.4574e-02,\n",
      "          -1.5040e-01,  2.6233e-01,  9.7431e-02, -2.7222e-01,  9.4101e-04,\n",
      "           1.8520e-01,  1.1372e-01, -1.6920e-01, -1.4935e-01, -1.7876e-01,\n",
      "           1.3002e-01,  6.6238e-03, -3.0325e-02, -5.2365e-03, -3.1567e-02,\n",
      "           1.7663e-01, -3.3783e-01, -8.1890e-02,  1.2231e-01,  1.4565e-01,\n",
      "          -6.2686e-02, -1.8863e-01,  1.6398e-01, -7.0476e-02, -1.3473e-01,\n",
      "           2.2804e-01, -1.6154e-01, -3.4120e-01,  3.6032e-01,  5.7981e-02,\n",
      "          -1.4718e-01, -4.6155e-01, -8.4446e-02],\n",
      "         [ 1.1022e-01,  2.0317e-04, -2.5000e-01, -6.6160e-03, -7.8894e-02,\n",
      "           9.3058e-02, -6.6140e-03,  8.7926e-02,  5.5190e-02, -1.6921e-02,\n",
      "          -3.2447e-01, -7.8613e-02, -7.6491e-02,  5.1582e-02, -2.4951e-01,\n",
      "           9.8667e-02, -1.2694e-01, -1.2645e-01,  1.4784e-01, -2.5775e-01,\n",
      "          -1.4721e-01, -1.7751e-01,  1.1342e-01,  7.8821e-02,  4.5060e-03,\n",
      "           2.8182e-02, -6.4579e-02,  2.6689e-02,  3.1899e-01,  2.9444e-01,\n",
      "          -1.4225e-01,  4.1455e-02,  4.8149e-02, -2.0463e-01,  1.1844e-02,\n",
      "          -1.7983e-02,  5.1505e-02,  1.3553e-01, -7.6996e-02, -6.8375e-02,\n",
      "           8.9655e-02, -1.2584e-01,  1.8808e-02,  1.0315e-01,  1.2718e-01,\n",
      "           1.9659e-01, -7.3689e-02, -7.1922e-02],\n",
      "         [-1.1548e-01, -1.6214e-01, -2.0409e-01,  1.5278e-02, -7.9132e-02,\n",
      "          -1.6488e-01,  1.3085e-01, -1.0183e-01,  9.5950e-02, -4.6311e-02,\n",
      "           2.4868e-02,  1.7883e-01, -2.7886e-01, -1.4746e-01,  1.9873e-01,\n",
      "           9.7039e-02, -6.6805e-02, -1.0157e-01,  3.2921e-01,  9.4494e-02,\n",
      "           1.0995e-01,  1.0850e-01,  1.5272e-01, -3.3165e-02,  1.7177e-02,\n",
      "           2.4641e-01,  1.4665e-01, -2.2639e-01,  1.2947e-01,  1.9803e-01,\n",
      "           9.1801e-02,  3.5669e-02,  3.3131e-01,  4.0226e-02,  1.5720e-01,\n",
      "          -4.0217e-02,  1.3078e-01, -6.3419e-02,  7.4202e-02, -8.2714e-02,\n",
      "          -1.9721e-02, -8.6467e-02,  1.6093e-01, -2.4204e-01, -1.2334e-01,\n",
      "          -2.1713e-01,  2.4863e-01,  4.5835e-02]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[0.4603],\n",
      "         [0.3012],\n",
      "         [0.3489]],\n",
      "\n",
      "        [[0.4453],\n",
      "         [0.3377],\n",
      "         [0.3661]],\n",
      "\n",
      "        [[0.4337],\n",
      "         [0.3633],\n",
      "         [0.3777]],\n",
      "\n",
      "        [[0.4228],\n",
      "         [0.3793],\n",
      "         [0.3855]],\n",
      "\n",
      "        [[0.4149],\n",
      "         [0.3884],\n",
      "         [0.3909]],\n",
      "\n",
      "        [[0.4097],\n",
      "         [0.3935],\n",
      "         [0.3946]],\n",
      "\n",
      "        [[0.4063],\n",
      "         [0.3965],\n",
      "         [0.3969]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 12 is -0.4842714744443865\n",
      "tensor([[[-0.2646,  0.2154, -0.0636,  0.1115,  0.1523,  0.1686, -0.0433,\n",
      "           0.0097, -0.2388,  0.3776,  0.0520, -0.1705, -0.0298,  0.2559,\n",
      "           0.0575, -0.1593,  0.2724,  0.0885, -0.2856,  0.0034,  0.1992,\n",
      "           0.1200, -0.1811, -0.1636, -0.1939,  0.1378,  0.0140, -0.0389,\n",
      "          -0.0057, -0.0352,  0.1865, -0.3473, -0.0765,  0.1370,  0.1542,\n",
      "          -0.0614, -0.2057,  0.1722, -0.0656, -0.1373,  0.2368, -0.1816,\n",
      "          -0.3570,  0.3710,  0.0556, -0.1633, -0.4810, -0.0945],\n",
      "         [ 0.1159,  0.0041, -0.2712, -0.0040, -0.0815,  0.0794, -0.0018,\n",
      "           0.0939,  0.0587, -0.0339, -0.3316, -0.0636, -0.0748,  0.0443,\n",
      "          -0.2580,  0.1038, -0.1384, -0.1315,  0.1511, -0.2626, -0.1534,\n",
      "          -0.1853,  0.1098,  0.0853,  0.0055,  0.0330, -0.0663,  0.0273,\n",
      "           0.3342,  0.3048, -0.1430,  0.0411,  0.0560, -0.2051,  0.0132,\n",
      "          -0.0148,  0.0642,  0.1303, -0.0848, -0.0664,  0.0877, -0.1276,\n",
      "           0.0353,  0.0925,  0.1384,  0.1980, -0.0719, -0.0707],\n",
      "         [-0.1104, -0.1603, -0.2199,  0.0168, -0.0794, -0.1668,  0.1299,\n",
      "          -0.1041,  0.0978, -0.0524,  0.0239,  0.1910, -0.2798, -0.1598,\n",
      "           0.1964,  0.0999, -0.0706, -0.1100,  0.3255,  0.0973,  0.1008,\n",
      "           0.1032,  0.1476, -0.0318,  0.0148,  0.2506,  0.1509, -0.2297,\n",
      "           0.1371,  0.1996,  0.0883,  0.0312,  0.3344,  0.0386,  0.1586,\n",
      "          -0.0417,  0.1364, -0.0654,  0.0736, -0.0777, -0.0162, -0.0888,\n",
      "           0.1681, -0.2565, -0.1186, -0.2157,  0.2474,  0.0470]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.5018],\n",
      "         [0.3198],\n",
      "         [0.3711]],\n",
      "\n",
      "        [[0.4877],\n",
      "         [0.3589],\n",
      "         [0.3906]],\n",
      "\n",
      "        [[0.4718],\n",
      "         [0.3870],\n",
      "         [0.4034]],\n",
      "\n",
      "        [[0.4586],\n",
      "         [0.4048],\n",
      "         [0.4130]],\n",
      "\n",
      "        [[0.4493],\n",
      "         [0.4162],\n",
      "         [0.4199]],\n",
      "\n",
      "        [[0.4429],\n",
      "         [0.4229],\n",
      "         [0.4243]],\n",
      "\n",
      "        [[0.4389],\n",
      "         [0.4266],\n",
      "         [0.4272]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 13 is -0.4399919472821779\n",
      "tensor([[[-0.2813,  0.2143, -0.0553,  0.1124,  0.1720,  0.1867, -0.0447,\n",
      "           0.0052, -0.2500,  0.3962,  0.0488, -0.1889, -0.0249,  0.2680,\n",
      "           0.0706, -0.1769,  0.2894,  0.0992, -0.3168,  0.0042,  0.2230,\n",
      "           0.1422, -0.1791, -0.1846, -0.2069,  0.1390,  0.0057, -0.0352,\n",
      "          -0.0146, -0.0480,  0.1977, -0.3514, -0.0910,  0.1527,  0.1515,\n",
      "          -0.0596, -0.2310,  0.1927, -0.0600, -0.1402,  0.2376, -0.1959,\n",
      "          -0.3764,  0.3884,  0.0433, -0.1692, -0.4940, -0.0963],\n",
      "         [ 0.1061, -0.0091, -0.2900,  0.0021, -0.0892,  0.0801,  0.0179,\n",
      "           0.0851,  0.0532, -0.0346, -0.3461, -0.0631, -0.0830,  0.0442,\n",
      "          -0.2602,  0.0999, -0.1363, -0.1296,  0.1583, -0.2762, -0.1622,\n",
      "          -0.1822,  0.1294,  0.0889,  0.0127,  0.0301, -0.0822,  0.0441,\n",
      "           0.3512,  0.3134, -0.1389,  0.0618,  0.0459, -0.2072,  0.0039,\n",
      "          -0.0119,  0.0694,  0.1443, -0.0931, -0.0676,  0.0731, -0.1252,\n",
      "           0.0372,  0.0936,  0.1381,  0.2037, -0.0626, -0.0626],\n",
      "         [-0.1130, -0.1678, -0.2288,  0.0248, -0.0849, -0.1648,  0.1415,\n",
      "          -0.1200,  0.0949, -0.0469,  0.0122,  0.1923, -0.2925, -0.1546,\n",
      "           0.1897,  0.0932, -0.0639, -0.1026,  0.3336,  0.1008,  0.0987,\n",
      "           0.1108,  0.1528, -0.0339,  0.0182,  0.2463,  0.1371, -0.2206,\n",
      "           0.1356,  0.1991,  0.0915,  0.0519,  0.3306,  0.0369,  0.1505,\n",
      "          -0.0430,  0.1360, -0.0595,  0.0697, -0.0768, -0.0244, -0.0808,\n",
      "           0.1622, -0.2462, -0.1226, -0.2081,  0.2490,  0.0568]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.5382],\n",
      "         [0.3253],\n",
      "         [0.3810]],\n",
      "\n",
      "        [[0.5203],\n",
      "         [0.3671],\n",
      "         [0.4033]],\n",
      "\n",
      "        [[0.5018],\n",
      "         [0.3989],\n",
      "         [0.4184]],\n",
      "\n",
      "        [[0.4858],\n",
      "         [0.4191],\n",
      "         [0.4294]],\n",
      "\n",
      "        [[0.4743],\n",
      "         [0.4319],\n",
      "         [0.4371]],\n",
      "\n",
      "        [[0.4666],\n",
      "         [0.4398],\n",
      "         [0.4424]],\n",
      "\n",
      "        [[0.4613],\n",
      "         [0.4447],\n",
      "         [0.4459]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 14 is -0.4028515813263802\n",
      "tensor([[[-0.3207,  0.1568, -0.0249,  0.1256,  0.2203,  0.2400, -0.0241,\n",
      "          -0.0136, -0.2751,  0.4198,  0.0236, -0.2287, -0.0360,  0.2793,\n",
      "           0.0778, -0.2043,  0.3073,  0.1508, -0.3839,  0.0023,  0.2705,\n",
      "           0.1905, -0.1253, -0.2218, -0.2097,  0.1289, -0.0311, -0.0036,\n",
      "          -0.0529, -0.0869,  0.2080, -0.3400, -0.1419,  0.1660,  0.1260,\n",
      "          -0.0517, -0.2676,  0.2375, -0.0528, -0.1448,  0.2083, -0.1847,\n",
      "          -0.3948,  0.4031,  0.0144, -0.1511, -0.4871, -0.0778],\n",
      "         [ 0.0596, -0.0450, -0.2891,  0.0221, -0.1067,  0.1195,  0.0746,\n",
      "           0.0449,  0.0238,  0.0039, -0.3659, -0.1038, -0.1116,  0.0547,\n",
      "          -0.2462,  0.0767, -0.1026, -0.0994,  0.1716, -0.3097, -0.1739,\n",
      "          -0.1537,  0.1974,  0.0888,  0.0334,  0.0083, -0.1258,  0.0929,\n",
      "           0.3608,  0.3190, -0.1196,  0.1244, -0.0079, -0.2105, -0.0281,\n",
      "          -0.0135,  0.0572,  0.1900, -0.1010, -0.0691,  0.0271, -0.1099,\n",
      "           0.0047,  0.1141,  0.1077,  0.2196, -0.0367, -0.0364],\n",
      "         [-0.1302, -0.1836, -0.2064,  0.0495, -0.1023, -0.1479,  0.1835,\n",
      "          -0.1589,  0.0772, -0.0159, -0.0217,  0.1571, -0.3318, -0.1143,\n",
      "           0.1752,  0.0669, -0.0363, -0.0446,  0.3664,  0.1043,  0.1124,\n",
      "           0.1416,  0.1815, -0.0437,  0.0343,  0.2217,  0.0817, -0.1812,\n",
      "           0.0997,  0.1931,  0.1082,  0.1261,  0.3050,  0.0353,  0.1228,\n",
      "          -0.0443,  0.1218, -0.0365,  0.0591, -0.0822, -0.0602, -0.0423,\n",
      "           0.1242, -0.1800, -0.1443, -0.1834,  0.2574,  0.0848]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.5652],\n",
      "         [0.3196],\n",
      "         [0.3792]],\n",
      "\n",
      "        [[0.5445],\n",
      "         [0.3650],\n",
      "         [0.4055]],\n",
      "\n",
      "        [[0.5234],\n",
      "         [0.3985],\n",
      "         [0.4207]],\n",
      "\n",
      "        [[0.5036],\n",
      "         [0.4200],\n",
      "         [0.4322]],\n",
      "\n",
      "        [[0.4884],\n",
      "         [0.4339],\n",
      "         [0.4408]],\n",
      "\n",
      "        [[0.4781],\n",
      "         [0.4426],\n",
      "         [0.4467]],\n",
      "\n",
      "        [[0.4710],\n",
      "         [0.4484],\n",
      "         [0.4507]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 15 is -0.37369742987995686\n",
      "tensor([[[-0.3443,  0.1377,  0.0067,  0.1332,  0.2532,  0.2777, -0.0190,\n",
      "          -0.0242, -0.2800,  0.4548,  0.0210, -0.2543, -0.0370,  0.3154,\n",
      "           0.0886, -0.2375,  0.3382,  0.1805, -0.4229, -0.0022,  0.2994,\n",
      "           0.2268, -0.1003, -0.2494, -0.2148,  0.1210, -0.0477,  0.0108,\n",
      "          -0.0706, -0.1104,  0.2267, -0.3484, -0.1817,  0.1861,  0.1156,\n",
      "          -0.0542, -0.3066,  0.2565, -0.0480, -0.1509,  0.2063, -0.1768,\n",
      "          -0.4037,  0.4372, -0.0065, -0.1430, -0.4959, -0.0673],\n",
      "         [ 0.0358, -0.0716, -0.2794,  0.0267, -0.1139,  0.1391,  0.1167,\n",
      "           0.0220,  0.0027,  0.0260, -0.4066, -0.1280, -0.1547,  0.0664,\n",
      "          -0.2405,  0.0615, -0.0903, -0.0722,  0.1837, -0.3206, -0.1916,\n",
      "          -0.1327,  0.2569,  0.0851,  0.0568, -0.0048, -0.1525,  0.1285,\n",
      "           0.3434,  0.3216, -0.1268,  0.1826, -0.0511, -0.2275, -0.0488,\n",
      "          -0.0061,  0.0471,  0.2219, -0.1076, -0.0796, -0.0100, -0.0893,\n",
      "          -0.0136,  0.1238,  0.0978,  0.2401, -0.0148, -0.0220],\n",
      "         [-0.1415, -0.1975, -0.1611,  0.0682, -0.1035, -0.1304,  0.1951,\n",
      "          -0.1850,  0.0607,  0.0036, -0.0405,  0.1187, -0.3472, -0.0863,\n",
      "           0.1716,  0.0502, -0.0212,  0.0253,  0.3715,  0.0971,  0.1212,\n",
      "           0.1590,  0.1990, -0.0490,  0.0497,  0.2004,  0.0449, -0.1516,\n",
      "           0.0625,  0.1910,  0.1188,  0.1780,  0.2793,  0.0318,  0.1051,\n",
      "          -0.0489,  0.1086, -0.0212,  0.0524, -0.0926, -0.0859, -0.0122,\n",
      "           0.0891, -0.1289, -0.1609, -0.1669,  0.2632,  0.0957]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.5870],\n",
      "         [0.3027],\n",
      "         [0.3681]],\n",
      "\n",
      "        [[0.5603],\n",
      "         [0.3478],\n",
      "         [0.3953]],\n",
      "\n",
      "        [[0.5355],\n",
      "         [0.3834],\n",
      "         [0.4119]],\n",
      "\n",
      "        [[0.5106],\n",
      "         [0.4073],\n",
      "         [0.4245]],\n",
      "\n",
      "        [[0.4912],\n",
      "         [0.4230],\n",
      "         [0.4336]],\n",
      "\n",
      "        [[0.4780],\n",
      "         [0.4338],\n",
      "         [0.4399]],\n",
      "\n",
      "        [[0.4688],\n",
      "         [0.4406],\n",
      "         [0.4441]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 16 is -0.3701702093367748\n",
      "tensor([[[-0.3417,  0.2250, -0.0118,  0.1083,  0.2246,  0.2365, -0.0501,\n",
      "           0.0020, -0.2628,  0.4845,  0.0573, -0.2425, -0.0188,  0.3592,\n",
      "           0.1049, -0.2523,  0.3639,  0.1133, -0.3843,  0.0030,  0.2905,\n",
      "           0.2081, -0.1639, -0.2536, -0.2400,  0.1478, -0.0019, -0.0303,\n",
      "          -0.0393, -0.0878,  0.2454, -0.3810, -0.1406,  0.2051,  0.1594,\n",
      "          -0.0647, -0.3315,  0.2354, -0.0440, -0.1697,  0.2650, -0.2212,\n",
      "          -0.4194,  0.4736,  0.0122, -0.1966, -0.5333, -0.1065],\n",
      "         [ 0.0848, -0.0548, -0.3044,  0.0156, -0.0959,  0.0869,  0.0734,\n",
      "           0.0628,  0.0382, -0.0309, -0.4279, -0.0837, -0.1541,  0.0559,\n",
      "          -0.2755,  0.0862, -0.1360, -0.1054,  0.1846, -0.2994, -0.1957,\n",
      "          -0.1707,  0.2431,  0.0964,  0.0511,  0.0144, -0.1414,  0.0990,\n",
      "           0.3473,  0.3418, -0.1532,  0.1694, -0.0091, -0.2455, -0.0371,\n",
      "           0.0052,  0.0744,  0.1761, -0.1218, -0.0825,  0.0308, -0.1066,\n",
      "           0.0315,  0.1051,  0.1477,  0.2472, -0.0265, -0.0445],\n",
      "         [-0.1277, -0.1908, -0.1853,  0.0556, -0.0811, -0.1488,  0.1474,\n",
      "          -0.1512,  0.0791, -0.0263, -0.0132,  0.1522, -0.3103, -0.1205,\n",
      "           0.1830,  0.0777, -0.0461, -0.0189,  0.3288,  0.0898,  0.1014,\n",
      "           0.1258,  0.1745, -0.0382,  0.0410,  0.2182,  0.0860, -0.1808,\n",
      "           0.0953,  0.1996,  0.0995,  0.1197,  0.3057,  0.0250,  0.1279,\n",
      "          -0.0546,  0.1211, -0.0449,  0.0588, -0.0925, -0.0511, -0.0487,\n",
      "           0.1199, -0.1890, -0.1377, -0.1844,  0.2575,  0.0634]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.6042],\n",
      "         [0.2694],\n",
      "         [0.3485]],\n",
      "\n",
      "        [[0.5700],\n",
      "         [0.3160],\n",
      "         [0.3736]],\n",
      "\n",
      "        [[0.5393],\n",
      "         [0.3568],\n",
      "         [0.3928]],\n",
      "\n",
      "        [[0.5121],\n",
      "         [0.3854],\n",
      "         [0.4073]],\n",
      "\n",
      "        [[0.4897],\n",
      "         [0.4047],\n",
      "         [0.4178]],\n",
      "\n",
      "        [[0.4730],\n",
      "         [0.4175],\n",
      "         [0.4251]],\n",
      "\n",
      "        [[0.4617],\n",
      "         [0.4259],\n",
      "         [0.4303]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 17 is -0.37014193521210975\n",
      "tensor([[[-0.3528,  0.2523, -0.0135,  0.1013,  0.2430,  0.2410, -0.0626,\n",
      "           0.0061, -0.2811,  0.4941,  0.0641, -0.2620, -0.0091,  0.3659,\n",
      "           0.1204, -0.2699,  0.3783,  0.1097, -0.4150,  0.0061,  0.3059,\n",
      "           0.2188, -0.1876, -0.2718, -0.2640,  0.1564,  0.0051, -0.0420,\n",
      "          -0.0400, -0.0911,  0.2495, -0.3872, -0.1340,  0.2232,  0.1700,\n",
      "          -0.0685, -0.3584,  0.2529, -0.0396, -0.1719,  0.2852, -0.2604,\n",
      "          -0.4453,  0.4881,  0.0078, -0.2189, -0.5549, -0.1241],\n",
      "         [ 0.0945, -0.0505, -0.3428,  0.0213, -0.1042,  0.0726,  0.0789,\n",
      "           0.0671,  0.0490, -0.0572, -0.4316, -0.0675, -0.1689,  0.0445,\n",
      "          -0.2892,  0.0932, -0.1454, -0.1209,  0.2009, -0.3162, -0.2059,\n",
      "          -0.1836,  0.2510,  0.1079,  0.0540,  0.0184, -0.1417,  0.1014,\n",
      "           0.3838,  0.3591, -0.1518,  0.1710,  0.0009, -0.2489, -0.0401,\n",
      "           0.0098,  0.0900,  0.1676, -0.1356, -0.0814,  0.0330, -0.1115,\n",
      "           0.0486,  0.0927,  0.1646,  0.2451, -0.0227, -0.0463],\n",
      "         [-0.1231, -0.1842, -0.2070,  0.0581, -0.0845, -0.1552,  0.1520,\n",
      "          -0.1477,  0.0860, -0.0353, -0.0106,  0.1688, -0.3174, -0.1268,\n",
      "           0.1782,  0.0814, -0.0494, -0.0313,  0.3362,  0.0943,  0.0960,\n",
      "           0.1191,  0.1703, -0.0359,  0.0392,  0.2197,  0.0934, -0.1838,\n",
      "           0.1087,  0.2009,  0.0904,  0.1066,  0.3127,  0.0199,  0.1296,\n",
      "          -0.0534,  0.1242, -0.0494,  0.0592, -0.0863, -0.0440, -0.0557,\n",
      "           0.1311, -0.2028, -0.1292, -0.1834,  0.2543,  0.0617]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.6206],\n",
      "         [0.2333],\n",
      "         [0.3239]],\n",
      "\n",
      "        [[0.5830],\n",
      "         [0.2829],\n",
      "         [0.3519]],\n",
      "\n",
      "        [[0.5460],\n",
      "         [0.3278],\n",
      "         [0.3729]],\n",
      "\n",
      "        [[0.5146],\n",
      "         [0.3606],\n",
      "         [0.3893]],\n",
      "\n",
      "        [[0.4880],\n",
      "         [0.3847],\n",
      "         [0.4013]],\n",
      "\n",
      "        [[0.4682],\n",
      "         [0.4001],\n",
      "         [0.4098]],\n",
      "\n",
      "        [[0.4544],\n",
      "         [0.4100],\n",
      "         [0.4156]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 18 is -0.37204845076395204\n",
      "tensor([[[-0.3621,  0.2951, -0.0148,  0.0928,  0.2522,  0.2397, -0.0709,\n",
      "           0.0146, -0.2905,  0.5124,  0.0758, -0.2727,  0.0011,  0.3858,\n",
      "           0.1362, -0.2893,  0.3979,  0.0958, -0.4265,  0.0088,  0.3191,\n",
      "           0.2261, -0.2112, -0.2933, -0.2904,  0.1712,  0.0180, -0.0567,\n",
      "          -0.0371, -0.0934,  0.2651, -0.4012, -0.1276,  0.2420,  0.1869,\n",
      "          -0.0757, -0.3877,  0.2630, -0.0347, -0.1803,  0.3096, -0.2999,\n",
      "          -0.4678,  0.5110,  0.0073, -0.2503, -0.5798, -0.1445],\n",
      "         [ 0.1078, -0.0465, -0.3723,  0.0247, -0.1061,  0.0500,  0.0828,\n",
      "           0.0736,  0.0608, -0.0867, -0.4436, -0.0464, -0.1769,  0.0348,\n",
      "          -0.3070,  0.1019, -0.1642, -0.1350,  0.2084, -0.3233, -0.2150,\n",
      "          -0.1988,  0.2532,  0.1201,  0.0564,  0.0254, -0.1460,  0.1018,\n",
      "           0.4032,  0.3744, -0.1569,  0.1722,  0.0173, -0.2525, -0.0385,\n",
      "           0.0169,  0.1095,  0.1545, -0.1518, -0.0781,  0.0374, -0.1139,\n",
      "           0.0731,  0.0796,  0.1872,  0.2472, -0.0196, -0.0465],\n",
      "         [-0.1158, -0.1811, -0.2261,  0.0567, -0.0824, -0.1601,  0.1464,\n",
      "          -0.1453,  0.0915, -0.0467, -0.0081,  0.1845, -0.3151, -0.1416,\n",
      "           0.1776,  0.0884, -0.0576, -0.0490,  0.3281,  0.0953,  0.0847,\n",
      "           0.1084,  0.1633, -0.0330,  0.0361,  0.2266,  0.1040, -0.1920,\n",
      "           0.1210,  0.2036,  0.0820,  0.0940,  0.3205,  0.0164,  0.1340,\n",
      "          -0.0543,  0.1307, -0.0547,  0.0602, -0.0801, -0.0355, -0.0619,\n",
      "           0.1441, -0.2252, -0.1202, -0.1848,  0.2521,  0.0590]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.6382],\n",
      "         [0.1977],\n",
      "         [0.3003]],\n",
      "\n",
      "        [[0.5995],\n",
      "         [0.2495],\n",
      "         [0.3293]],\n",
      "\n",
      "        [[0.5576],\n",
      "         [0.2992],\n",
      "         [0.3520]],\n",
      "\n",
      "        [[0.5201],\n",
      "         [0.3363],\n",
      "         [0.3703]],\n",
      "\n",
      "        [[0.4895],\n",
      "         [0.3635],\n",
      "         [0.3842]],\n",
      "\n",
      "        [[0.4659],\n",
      "         [0.3818],\n",
      "         [0.3944]],\n",
      "\n",
      "        [[0.4494],\n",
      "         [0.3939],\n",
      "         [0.4012]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 19 is -0.3756151712564593\n",
      "tensor([[[-0.3780,  0.3145, -0.0107,  0.0889,  0.2750,  0.2528, -0.0740,\n",
      "           0.0170, -0.3094,  0.5292,  0.0789, -0.2912,  0.0072,  0.3981,\n",
      "           0.1477, -0.3099,  0.4170,  0.0984, -0.4543,  0.0109,  0.3406,\n",
      "           0.2439, -0.2195, -0.3211, -0.3159,  0.1833,  0.0202, -0.0616,\n",
      "          -0.0439, -0.1059,  0.2782, -0.4085, -0.1351,  0.2585,  0.1953,\n",
      "          -0.0798, -0.4179,  0.2867, -0.0294, -0.1893,  0.3248, -0.3361,\n",
      "          -0.4917,  0.5290,  0.0009, -0.2734, -0.5973, -0.1605],\n",
      "         [ 0.1088, -0.0503, -0.4032,  0.0331, -0.1144,  0.0386,  0.1011,\n",
      "           0.0656,  0.0650, -0.1014, -0.4530, -0.0356, -0.1905,  0.0290,\n",
      "          -0.3196,  0.1036, -0.1703, -0.1433,  0.2200, -0.3397, -0.2260,\n",
      "          -0.2054,  0.2638,  0.1319,  0.0621,  0.0255, -0.1595,  0.1138,\n",
      "           0.4289,  0.3888, -0.1548,  0.1823,  0.0202, -0.2543, -0.0427,\n",
      "           0.0201,  0.1244,  0.1533, -0.1678, -0.0739,  0.0302, -0.1129,\n",
      "           0.0866,  0.0747,  0.1989,  0.2501, -0.0116, -0.0398],\n",
      "         [-0.1129, -0.1810, -0.2424,  0.0610, -0.0864, -0.1606,  0.1528,\n",
      "          -0.1539,  0.0931, -0.0489, -0.0139,  0.1930, -0.3234, -0.1454,\n",
      "           0.1731,  0.0871, -0.0574, -0.0549,  0.3316,  0.0968,  0.0772,\n",
      "           0.1076,  0.1631, -0.0320,  0.0371,  0.2261,  0.1003, -0.1901,\n",
      "           0.1273,  0.2046,  0.0802,  0.0989,  0.3204,  0.0140,  0.1309,\n",
      "          -0.0548,  0.1341, -0.0538,  0.0586, -0.0734, -0.0365, -0.0594,\n",
      "           0.1479, -0.2291, -0.1179, -0.1802,  0.2519,  0.0651]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.6674],\n",
      "         [0.1647],\n",
      "         [0.2782]],\n",
      "\n",
      "        [[0.6236],\n",
      "         [0.2190],\n",
      "         [0.3099]],\n",
      "\n",
      "        [[0.5793],\n",
      "         [0.2726],\n",
      "         [0.3342]],\n",
      "\n",
      "        [[0.5345],\n",
      "         [0.3142],\n",
      "         [0.3541]],\n",
      "\n",
      "        [[0.4985],\n",
      "         [0.3446],\n",
      "         [0.3696]],\n",
      "\n",
      "        [[0.4705],\n",
      "         [0.3654],\n",
      "         [0.3810]],\n",
      "\n",
      "        [[0.4505],\n",
      "         [0.3795],\n",
      "         [0.3892]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 20 is -0.37906808189280433\n",
      "tensor([[[-0.3962,  0.3370, -0.0042,  0.0850,  0.2968,  0.2672, -0.0749,\n",
      "           0.0204, -0.3246,  0.5537,  0.0854, -0.3083,  0.0121,  0.4214,\n",
      "           0.1586, -0.3354,  0.4426,  0.1000, -0.4775,  0.0122,  0.3615,\n",
      "           0.2649, -0.2273, -0.3512, -0.3411,  0.1965,  0.0241, -0.0668,\n",
      "          -0.0500, -0.1202,  0.2964, -0.4204, -0.1482,  0.2775,  0.2067,\n",
      "          -0.0863, -0.4510,  0.3090, -0.0242, -0.2019,  0.3446, -0.3689,\n",
      "          -0.5141,  0.5545, -0.0060, -0.2994, -0.6157, -0.1762],\n",
      "         [ 0.1096, -0.0572, -0.4270,  0.0401, -0.1197,  0.0290,  0.1192,\n",
      "           0.0557,  0.0673, -0.1131, -0.4703, -0.0286, -0.2095,  0.0262,\n",
      "          -0.3320,  0.1042, -0.1766, -0.1479,  0.2300, -0.3524, -0.2384,\n",
      "          -0.2101,  0.2806,  0.1419,  0.0706,  0.0242, -0.1774,  0.1290,\n",
      "           0.4447,  0.4022, -0.1570,  0.2008,  0.0189, -0.2607, -0.0497,\n",
      "           0.0253,  0.1367,  0.1534, -0.1846, -0.0720,  0.0228, -0.1095,\n",
      "           0.0957,  0.0718,  0.2114,  0.2575, -0.0025, -0.0328],\n",
      "         [-0.1121, -0.1838, -0.2489,  0.0664, -0.0874, -0.1592,  0.1550,\n",
      "          -0.1630,  0.0924, -0.0497, -0.0199,  0.1946, -0.3286, -0.1458,\n",
      "           0.1704,  0.0857, -0.0568, -0.0515,  0.3309,  0.0951,  0.0712,\n",
      "           0.1079,  0.1645, -0.0313,  0.0404,  0.2229,  0.0933, -0.1861,\n",
      "           0.1281,  0.2061,  0.0797,  0.1087,  0.3185,  0.0111,  0.1270,\n",
      "          -0.0567,  0.1355, -0.0522,  0.0566, -0.0701, -0.0387, -0.0548,\n",
      "           0.1468, -0.2273, -0.1180, -0.1752,  0.2531,  0.0693]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.7097],\n",
      "         [0.1360],\n",
      "         [0.2622]],\n",
      "\n",
      "        [[0.6592],\n",
      "         [0.1922],\n",
      "         [0.2958]],\n",
      "\n",
      "        [[0.6126],\n",
      "         [0.2497],\n",
      "         [0.3218]],\n",
      "\n",
      "        [[0.5624],\n",
      "         [0.2962],\n",
      "         [0.3435]],\n",
      "\n",
      "        [[0.5192],\n",
      "         [0.3302],\n",
      "         [0.3605]],\n",
      "\n",
      "        [[0.4854],\n",
      "         [0.3539],\n",
      "         [0.3734]],\n",
      "\n",
      "        [[0.4611],\n",
      "         [0.3703],\n",
      "         [0.3828]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 21 is -0.3817133336951008\n",
      "tensor([[[-4.2914e-01,  2.6463e-01,  3.6116e-02,  1.0204e-01,  3.8249e-01,\n",
      "           3.4099e-01, -5.6881e-02,  1.0514e-03, -3.6550e-01,  5.5779e-01,\n",
      "           5.9485e-02, -3.4940e-01,  4.4998e-03,  4.0383e-01,  1.5050e-01,\n",
      "          -3.5984e-01,  4.4978e-01,  1.7321e-01, -5.6500e-01,  1.0851e-02,\n",
      "           4.1083e-01,  3.1687e-01, -1.5566e-01, -3.9716e-01, -3.5655e-01,\n",
      "           1.8661e-01, -1.7508e-02, -2.9679e-02, -1.0117e-01, -1.7275e-01,\n",
      "           2.9686e-01, -4.1022e-01, -2.1458e-01,  2.9072e-01,  1.7553e-01,\n",
      "          -7.6914e-02, -4.7993e-01,  3.6318e-01, -2.0026e-02, -2.0208e-01,\n",
      "           3.2728e-01, -3.7737e-01, -5.2699e-01,  5.5265e-01, -3.4361e-02,\n",
      "          -2.8339e-01, -6.1432e-01, -1.5925e-01],\n",
      "         [ 5.7105e-02, -8.0630e-02, -4.5112e-01,  7.0444e-02, -1.5395e-01,\n",
      "           7.1435e-02,  2.0632e-01, -1.8501e-03,  3.4821e-02, -6.2236e-02,\n",
      "          -4.7751e-01, -7.8257e-02, -2.6793e-01,  3.7237e-02, -3.1428e-01,\n",
      "           7.8296e-02, -1.3349e-01, -1.1245e-01,  2.6708e-01, -4.0053e-01,\n",
      "          -2.6373e-01, -1.8016e-01,  3.3800e-01,  1.4753e-01,  9.4935e-02,\n",
      "          -3.3433e-03, -2.1179e-01,  1.8666e-01,  4.7324e-01,  4.1145e-01,\n",
      "          -1.3578e-01,  2.5544e-01, -4.2493e-02, -2.6281e-01, -7.9284e-02,\n",
      "           1.7582e-02,  1.2195e-01,  1.9936e-01, -1.9082e-01, -7.0229e-02,\n",
      "          -3.8190e-02, -8.0803e-02,  5.5240e-02,  9.0627e-02,  1.7519e-01,\n",
      "           2.6582e-01,  2.8589e-02, -1.0619e-04],\n",
      "         [-1.3035e-01, -1.8606e-01, -2.1028e-01,  1.0051e-01, -1.1260e-01,\n",
      "          -1.3301e-01,  2.1314e-01, -2.0248e-01,  7.1568e-02, -1.1790e-02,\n",
      "          -5.5426e-02,  1.4421e-01, -3.7852e-01, -9.5973e-02,  1.5536e-01,\n",
      "           5.5510e-02, -2.5456e-02,  3.3931e-02,  3.7591e-01,  9.5054e-02,\n",
      "           8.7511e-02,  1.4081e-01,  1.9660e-01, -4.0515e-02,  6.1145e-02,\n",
      "           1.8519e-01,  2.5600e-02, -1.3354e-01,  7.5448e-02,  1.9873e-01,\n",
      "           9.7487e-02,  1.8736e-01,  2.7955e-01,  9.0316e-03,  9.4551e-02,\n",
      "          -5.4423e-02,  1.1706e-01, -2.5906e-02,  4.6043e-02, -7.2101e-02,\n",
      "          -8.3016e-02, -1.4283e-03,  9.9805e-02, -1.4245e-01, -1.4461e-01,\n",
      "          -1.4185e-01,  2.6092e-01,  1.0272e-01]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[0.7546],\n",
      "         [0.1214],\n",
      "         [0.2566]],\n",
      "\n",
      "        [[0.7088],\n",
      "         [0.1786],\n",
      "         [0.2964]],\n",
      "\n",
      "        [[0.6577],\n",
      "         [0.2373],\n",
      "         [0.3218]],\n",
      "\n",
      "        [[0.6035],\n",
      "         [0.2871],\n",
      "         [0.3438]],\n",
      "\n",
      "        [[0.5539],\n",
      "         [0.3237],\n",
      "         [0.3614]],\n",
      "\n",
      "        [[0.5135],\n",
      "         [0.3499],\n",
      "         [0.3749]],\n",
      "\n",
      "        [[0.4826],\n",
      "         [0.3683],\n",
      "         [0.3849]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 22 is -0.3836886961809521\n",
      "tensor([[[-4.5314e-01,  2.4298e-01,  6.2633e-02,  1.0896e-01,  4.3189e-01,\n",
      "           3.8245e-01, -4.4015e-02, -4.3249e-03, -3.8093e-01,  5.7790e-01,\n",
      "           5.6759e-02, -3.6659e-01,  1.9781e-04,  4.1606e-01,  1.4654e-01,\n",
      "          -3.8416e-01,  4.6607e-01,  2.0166e-01, -5.9990e-01,  1.0682e-02,\n",
      "           4.4483e-01,  3.4877e-01, -1.1472e-01, -4.3630e-01, -3.7334e-01,\n",
      "           1.9528e-01, -2.5473e-02, -1.6111e-02, -1.2730e-01, -2.0929e-01,\n",
      "           3.1783e-01, -4.1912e-01, -2.5939e-01,  3.0930e-01,  1.7342e-01,\n",
      "          -7.6147e-02, -5.0768e-01,  3.9308e-01, -1.4261e-02, -2.1732e-01,\n",
      "           3.3472e-01, -3.8098e-01, -5.3645e-01,  5.6963e-01, -4.8098e-02,\n",
      "          -2.9869e-01, -6.2253e-01, -1.5615e-01],\n",
      "         [ 3.4219e-02, -9.4731e-02, -4.5017e-01,  8.8523e-02, -1.6402e-01,\n",
      "           9.8928e-02,  2.4623e-01, -4.4228e-02,  1.7184e-02, -4.0193e-02,\n",
      "          -4.9342e-01, -1.0549e-01, -3.0470e-01,  4.3583e-02, -3.1357e-01,\n",
      "           6.2427e-02, -1.1961e-01, -7.7631e-02,  2.8727e-01, -4.2234e-01,\n",
      "          -2.7993e-01, -1.6374e-01,  3.7454e-01,  1.5522e-01,  1.0984e-01,\n",
      "          -2.2432e-02, -2.3776e-01,  2.2005e-01,  4.7012e-01,  4.2468e-01,\n",
      "          -1.2933e-01,  2.9606e-01, -8.5864e-02, -2.7344e-01, -1.0161e-01,\n",
      "           1.5840e-02,  1.1762e-01,  2.1708e-01, -2.0147e-01, -6.5828e-02,\n",
      "          -7.0877e-02, -6.4368e-02,  3.3405e-02,  1.0082e-01,  1.5751e-01,\n",
      "           2.8076e-01,  4.7135e-02,  1.9791e-02],\n",
      "         [-1.3987e-01, -1.9033e-01, -1.6828e-01,  1.1652e-01, -1.2105e-01,\n",
      "          -1.1516e-01,  2.3618e-01, -2.2900e-01,  5.5257e-02,  5.3068e-03,\n",
      "          -7.7199e-02,  1.0743e-01, -3.9955e-01, -6.8030e-02,  1.4848e-01,\n",
      "           4.0583e-02, -1.3758e-02,  1.0166e-01,  3.8771e-01,  8.8357e-02,\n",
      "           9.3973e-02,  1.5598e-01,  2.1207e-01, -4.6227e-02,  7.6930e-02,\n",
      "           1.6274e-01, -1.0499e-02, -1.0151e-01,  3.1694e-02,  1.9600e-01,\n",
      "           1.0381e-01,  2.3506e-01,  2.5374e-01,  2.5522e-03,  7.7413e-02,\n",
      "          -5.2839e-02,  1.0473e-01, -8.7737e-03,  4.1106e-02, -7.9567e-02,\n",
      "          -1.1172e-01,  3.5134e-02,  6.8388e-02, -9.3004e-02, -1.5917e-01,\n",
      "          -1.2315e-01,  2.6366e-01,  1.1635e-01]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[0.8166],\n",
      "         [0.1098],\n",
      "         [0.2596]],\n",
      "\n",
      "        [[0.7766],\n",
      "         [0.1687],\n",
      "         [0.3014]],\n",
      "\n",
      "        [[0.7186],\n",
      "         [0.2314],\n",
      "         [0.3279]],\n",
      "\n",
      "        [[0.6604],\n",
      "         [0.2846],\n",
      "         [0.3511]],\n",
      "\n",
      "        [[0.6047],\n",
      "         [0.3245],\n",
      "         [0.3699]],\n",
      "\n",
      "        [[0.5588],\n",
      "         [0.3535],\n",
      "         [0.3845]],\n",
      "\n",
      "        [[0.5216],\n",
      "         [0.3744],\n",
      "         [0.3955]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 23 is -0.38858003450579\n",
      "tensor([[[-0.4670,  0.3450,  0.0372,  0.0877,  0.3897,  0.3449, -0.0586,\n",
      "           0.0259, -0.3648,  0.6390,  0.1003, -0.3544,  0.0146,  0.4979,\n",
      "           0.1653, -0.4141,  0.5247,  0.1327, -0.5498,  0.0145,  0.4416,\n",
      "           0.3477, -0.1963, -0.4553, -0.4022,  0.2388,  0.0242, -0.0611,\n",
      "          -0.0875, -0.1956,  0.3676, -0.4582, -0.2343,  0.3405,  0.2371,\n",
      "          -0.1009, -0.5407,  0.3875, -0.0061, -0.2579,  0.3976, -0.4215,\n",
      "          -0.5621,  0.6259, -0.0360, -0.3700, -0.6520, -0.2045],\n",
      "         [ 0.0809, -0.0947, -0.4481,  0.0724, -0.1314,  0.0571,  0.1909,\n",
      "          -0.0263,  0.0522, -0.0934, -0.5309, -0.0603, -0.2923,  0.0362,\n",
      "          -0.3526,  0.0831, -0.1640, -0.1131,  0.2657, -0.3974, -0.2780,\n",
      "          -0.1963,  0.3662,  0.1636,  0.1047, -0.0115, -0.2625,  0.2085,\n",
      "           0.4510,  0.4407, -0.1557,  0.3016, -0.0511, -0.2973, -0.1037,\n",
      "           0.0322,  0.1418,  0.1707, -0.2286, -0.0638, -0.0272, -0.0871,\n",
      "           0.0686,  0.0923,  0.2060,  0.3002,  0.0355,  0.0010],\n",
      "         [-0.1302, -0.2052, -0.1898,  0.0960, -0.0920, -0.1369,  0.1757,\n",
      "          -0.2097,  0.0728, -0.0219, -0.0599,  0.1418, -0.3565, -0.0945,\n",
      "           0.1589,  0.0634, -0.0368,  0.0527,  0.3373,  0.0779,  0.0761,\n",
      "           0.1279,  0.1904, -0.0380,  0.0687,  0.1804,  0.0226, -0.1289,\n",
      "           0.0687,  0.2056,  0.0851,  0.1968,  0.2849, -0.0089,  0.0963,\n",
      "          -0.0585,  0.1136, -0.0287,  0.0474, -0.0863, -0.0820, -0.0032,\n",
      "           0.0930, -0.1452, -0.1400, -0.1429,  0.2582,  0.0847]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0.9128],\n",
      "         [0.0890],\n",
      "         [0.2650]],\n",
      "\n",
      "        [[0.8699],\n",
      "         [0.1527],\n",
      "         [0.3033]],\n",
      "\n",
      "        [[0.8077],\n",
      "         [0.2235],\n",
      "         [0.3344]],\n",
      "\n",
      "        [[0.7398],\n",
      "         [0.2835],\n",
      "         [0.3612]],\n",
      "\n",
      "        [[0.6774],\n",
      "         [0.3287],\n",
      "         [0.3829]],\n",
      "\n",
      "        [[0.6243],\n",
      "         [0.3620],\n",
      "         [0.3998]],\n",
      "\n",
      "        [[0.5806],\n",
      "         [0.3863],\n",
      "         [0.4127]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 24 is -0.40050394814536827\n",
      "tensor([[[-4.8590e-01,  4.1288e-01,  2.2899e-02,  7.0232e-02,  3.8567e-01,\n",
      "           3.2775e-01, -6.8758e-02,  4.8950e-02, -3.8350e-01,  6.6669e-01,\n",
      "           1.2303e-01, -3.6933e-01,  2.5291e-02,  5.2273e-01,  1.8288e-01,\n",
      "          -4.3701e-01,  5.5782e-01,  1.0133e-01, -5.5793e-01,  2.0049e-02,\n",
      "           4.4561e-01,  3.5711e-01, -2.5649e-01, -4.7433e-01, -4.3702e-01,\n",
      "           2.6947e-01,  5.3000e-02, -9.4983e-02, -7.5359e-02, -1.9175e-01,\n",
      "           3.8204e-01, -4.7164e-01, -2.0953e-01,  3.5807e-01,  2.8155e-01,\n",
      "          -1.2136e-01, -5.6976e-01,  4.0876e-01, -2.8565e-04, -2.7778e-01,\n",
      "           4.3771e-01, -4.7670e-01, -5.9927e-01,  6.5310e-01, -2.9955e-02,\n",
      "          -4.1795e-01, -6.7021e-01, -2.5466e-01],\n",
      "         [ 1.1304e-01, -7.9278e-02, -4.7528e-01,  7.3992e-02, -1.2514e-01,\n",
      "           2.3845e-02,  1.7056e-01,  4.2023e-04,  7.9466e-02, -1.3648e-01,\n",
      "          -5.3644e-01, -2.5299e-02, -2.9711e-01,  1.9682e-02, -3.8299e-01,\n",
      "           1.0331e-01, -1.8466e-01, -1.4693e-01,  2.6316e-01, -4.0153e-01,\n",
      "          -2.7679e-01, -2.2408e-01,  3.5872e-01,  1.7629e-01,  1.0282e-01,\n",
      "           4.0488e-04, -2.6718e-01,  1.9434e-01,  4.7387e-01,  4.5672e-01,\n",
      "          -1.6119e-01,  2.8790e-01, -1.4213e-02, -3.0471e-01, -1.0137e-01,\n",
      "           4.0579e-02,  1.6577e-01,  1.2975e-01, -2.5318e-01, -5.8641e-02,\n",
      "           1.7053e-03, -1.0098e-01,  1.0002e-01,  7.1207e-02,  2.4708e-01,\n",
      "           3.0015e-01,  2.8050e-02, -1.1051e-02],\n",
      "         [-1.1772e-01, -1.9563e-01, -2.2487e-01,  8.8866e-02, -8.5428e-02,\n",
      "          -1.5175e-01,  1.5467e-01, -1.8119e-01,  8.7548e-02, -4.7011e-02,\n",
      "          -4.2125e-02,  1.7244e-01, -3.4496e-01, -1.2101e-01,  1.5833e-01,\n",
      "           8.1658e-02, -5.2591e-02,  4.3701e-03,  3.2511e-01,  7.8475e-02,\n",
      "           6.2309e-02,  1.0483e-01,  1.7532e-01, -3.0414e-02,  6.1358e-02,\n",
      "           1.9449e-01,  5.4441e-02, -1.5084e-01,  1.0147e-01,  2.1001e-01,\n",
      "           6.8509e-02,  1.5376e-01,  3.0624e-01, -1.3571e-02,  1.1069e-01,\n",
      "          -5.7972e-02,  1.2509e-01, -4.6264e-02,  5.1263e-02, -7.8340e-02,\n",
      "          -5.3893e-02, -3.0690e-02,  1.2245e-01, -1.9316e-01, -1.1642e-01,\n",
      "          -1.5281e-01,  2.5459e-01,  6.7947e-02]]], grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0077],\n",
      "         [0.0825],\n",
      "         [0.2767]],\n",
      "\n",
      "        [[0.9667],\n",
      "         [0.1486],\n",
      "         [0.3154]],\n",
      "\n",
      "        [[0.9083],\n",
      "         [0.2251],\n",
      "         [0.3489]],\n",
      "\n",
      "        [[0.8375],\n",
      "         [0.2902],\n",
      "         [0.3782]],\n",
      "\n",
      "        [[0.7669],\n",
      "         [0.3399],\n",
      "         [0.4025]],\n",
      "\n",
      "        [[0.7056],\n",
      "         [0.3772],\n",
      "         [0.4218]],\n",
      "\n",
      "        [[0.6560],\n",
      "         [0.4049],\n",
      "         [0.4367]]], grad_fn=<AddBackward0>)\n",
      "The batch loss for Iteration: 0 - Batch: 25 is -0.41410768317921265\n",
      "tensor([[[-5.0663e-01,  4.6264e-01,  1.7308e-02,  5.9719e-02,  3.9600e-01,\n",
      "           3.2542e-01, -7.3348e-02,  6.6880e-02, -4.0891e-01,  6.8819e-01,\n",
      "           1.3880e-01, -3.8508e-01,  3.2874e-02,  5.3870e-01,  1.9707e-01,\n",
      "          -4.5916e-01,  5.8239e-01,  8.8255e-02, -5.7348e-01,  2.4532e-02,\n",
      "           4.5571e-01,  3.7210e-01, -2.9660e-01, -4.9973e-01, -4.7194e-01,\n",
      "           2.9443e-01,  6.9716e-02, -1.1689e-01, -7.3031e-02, -1.9991e-01,\n",
      "           3.9926e-01, -4.8273e-01, -2.0187e-01,  3.7148e-01,  3.1257e-01,\n",
      "          -1.3976e-01, -5.9725e-01,  4.3289e-01,  5.3625e-03, -2.9525e-01,\n",
      "           4.6835e-01, -5.2904e-01, -6.3108e-01,  6.7672e-01, -2.9910e-02,\n",
      "          -4.5962e-01, -6.8543e-01, -3.0000e-01],\n",
      "         [ 1.3015e-01, -6.9385e-02, -4.9872e-01,  8.0709e-02, -1.2438e-01,\n",
      "           4.2832e-04,  1.6750e-01,  9.6187e-03,  9.6158e-02, -1.6374e-01,\n",
      "          -5.3835e-01, -1.8717e-03, -3.0367e-01,  6.8819e-03, -4.0683e-01,\n",
      "           1.1438e-01, -1.9795e-01, -1.7130e-01,  2.6569e-01, -4.1292e-01,\n",
      "          -2.7652e-01, -2.4320e-01,  3.5587e-01,  1.9044e-01,  1.0346e-01,\n",
      "           6.1306e-03, -2.7591e-01,  1.9109e-01,  4.9580e-01,  4.6992e-01,\n",
      "          -1.6092e-01,  2.7732e-01,  1.0403e-02, -3.0544e-01, -1.0196e-01,\n",
      "           4.4252e-02,  1.8665e-01,  1.0216e-01, -2.7519e-01, -4.9548e-02,\n",
      "           1.4758e-02, -1.0715e-01,  1.2316e-01,  5.6634e-02,  2.7514e-01,\n",
      "           2.9883e-01,  2.7106e-02, -1.2982e-02],\n",
      "         [-1.0668e-01, -1.8881e-01, -2.5586e-01,  8.4083e-02, -8.4702e-02,\n",
      "          -1.6053e-01,  1.4739e-01, -1.7052e-01,  9.6838e-02, -6.2819e-02,\n",
      "          -3.6931e-02,  1.9370e-01, -3.4386e-01, -1.4076e-01,  1.5430e-01,\n",
      "           9.1497e-02, -6.3096e-02, -3.2000e-02,  3.1940e-01,  8.0034e-02,\n",
      "           4.9444e-02,  8.8773e-02,  1.6542e-01, -2.5010e-02,  5.6885e-02,\n",
      "           2.0529e-01,  7.3145e-02, -1.6399e-01,  1.2428e-01,  2.1211e-01,\n",
      "           5.5824e-02,  1.3111e-01,  3.1895e-01, -1.5937e-02,  1.1750e-01,\n",
      "          -5.4913e-02,  1.3457e-01, -5.5423e-02,  5.3346e-02, -6.9301e-02,\n",
      "          -4.0075e-02, -4.2616e-02,  1.4338e-01, -2.2452e-01, -9.9687e-02,\n",
      "          -1.5627e-01,  2.5075e-01,  6.4357e-02]]], grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericliu/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m l_r \u001b[39m=\u001b[39m \u001b[39m0.00079\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m p_model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     input_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     target_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     n_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     target_len,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49ml_r,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#Y116sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/src/proption_model.py:479\u001b[0m, in \u001b[0;36mproportion_model.train\u001b[0;34m(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    470\u001b[0m for t in range(target_len):\n\u001b[1;32m    471\u001b[0m     # -------- recursive prediction----------\n\u001b[1;32m    472\u001b[0m     # print(t)\n\u001b[1;32m    473\u001b[0m     (\n\u001b[1;32m    474\u001b[0m         layer_output,\n\u001b[1;32m    475\u001b[0m         decoder_output,\n\u001b[1;32m    476\u001b[0m         (decoder_hn, decoder_cn),\n\u001b[1;32m    477\u001b[0m     ) = self.decoder_lstm.forward(decoder_input, decoder_cache)\n\u001b[0;32m--> 479\u001b[0m     # print(decoder_output.shape)\n\u001b[1;32m    480\u001b[0m     # print(layer_output.shape)\n\u001b[1;32m    482\u001b[0m     decoder_ouputs[t, :, :] = torch.squeeze(layer_output, dim = 1)\n\u001b[1;32m    484\u001b[0m     decoder_input = decoder_output\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/src/proption_model.py:194\u001b[0m, in \u001b[0;36mdecoder_lstm.forward\u001b[0;34m(self, x, encoder_cache)\u001b[0m\n\u001b[1;32m    185\u001b[0m (hn, cn) \u001b[39m=\u001b[39m encoder_cache\n\u001b[1;32m    187\u001b[0m \u001b[39m### commented the line due to the fact that we are running a batched-decoder LSTM\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m# if self.batch_first:\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m#     x = x.unsqueeze(1)\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m#     x = x.unsqueeze(0)\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m decoder_output, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (hn, cn))\n\u001b[1;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn)\n\u001b[1;32m    196\u001b[0m decoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_1(decoder_output)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    763\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m format_list(extract_stack(f, limit\u001b[39m=\u001b[39;49mlimit))\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n\u001b[1;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m result:\n\u001b[0;32m--> 366\u001b[0m         f\u001b[39m.\u001b[39;49mline\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39;49mgetline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineno)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:16\u001b[0m, in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetline\u001b[39m(filename, lineno, module_globals\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     lines \u001b[39m=\u001b[39m getlines(filename, module_globals)\n\u001b[1;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lineno \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lines):\n\u001b[1;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m lines[lineno\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:44\u001b[0m, in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     42\u001b[0m     entry \u001b[39m=\u001b[39m cache[filename]\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(entry) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m cache[filename][\u001b[39m2\u001b[39m]\n\u001b[1;32m     46\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m module_globals \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "### convert np array into torch array \n",
    "input_tensor = torch.tensor(input_array).float()\n",
    "target_tensor = torch.tensor(target_array).float()\n",
    "\n",
    "###---------- dimension on the model hypter-parameters from the paper ------------ ######\n",
    "no_child = 3060 \n",
    "num_hts_embedd = no_child\n",
    "hts_embedd_dim = 8\n",
    "covariate_dim = 0\n",
    "\n",
    "lstm_input_dim = 2 + covariate_dim + hts_embedd_dim\n",
    "lstm_hidden_dim = 48\n",
    "lstm_num_layer = 1\n",
    "lstm_output_dim = 64\n",
    "\n",
    "mha_embedd_dim = lstm_output_dim\n",
    "num_head = 4\n",
    "num_attention_layer = 1\n",
    "mha_output_dim = mha_embedd_dim\n",
    "residual_output_dim = mha_output_dim\n",
    "model_ouput_dim = 1\n",
    "\n",
    "# define the model object\n",
    "p_model = proption_model.proportion_model(\n",
    "    num_hts_embedd,\n",
    "    hts_embedd_dim,  # ts embedding hyper pars\n",
    "    lstm_input_dim,\n",
    "    lstm_hidden_dim,\n",
    "    lstm_num_layer,\n",
    "    lstm_output_dim,  # lstm hyper pars\n",
    "    mha_embedd_dim,\n",
    "    num_head,\n",
    "    num_attention_layer,  # mha hyper pars\n",
    "    mha_output_dim,\n",
    "    residual_output_dim,  # skip connection hyper pars\n",
    "    model_ouput_dim,  # output later hyper pars\n",
    ")\n",
    "\n",
    "###---------- trainign parameters from the paper ------------ ######\n",
    "\n",
    "n_epochs = 50\n",
    "target_len = Forward\n",
    "batch_size = 1\n",
    "l_r = 0.00079\n",
    "\n",
    "# start training\n",
    "p_model.train(\n",
    "    input_tensor,\n",
    "    target_tensor,\n",
    "    n_epochs,\n",
    "    target_len,\n",
    "    batch_size,\n",
    "    learning_rate=l_r,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## PROD CODE FOLLOWING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_id  dept_id      item_id  id\n",
       "0  FOODS  FOODS_1  FOODS_1_001  10\n",
       "1  FOODS  FOODS_1  FOODS_1_002  10\n",
       "2  FOODS  FOODS_1  FOODS_1_003  10\n",
       "3  FOODS  FOODS_1  FOODS_1_004  10\n",
       "4  FOODS  FOODS_1  FOODS_1_005  10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_prod = sales_train_validation.groupby(groupby_list[2:]).count()[['id']].reset_index()\n",
    "hl_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = hl_prod\n",
    "df_right = sales_train_validation.groupby('item_id').sum()\n",
    "df = df_left.merge(df_right, left_on='item_id', right_index=True, how='inner').drop(columns=['id'])\n",
    "df.rename(columns=d_to_date, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>2011-01-29</th>\n",
       "      <th>2011-01-30</th>\n",
       "      <th>2011-01-31</th>\n",
       "      <th>2011-02-01</th>\n",
       "      <th>2011-02-02</th>\n",
       "      <th>2011-02-03</th>\n",
       "      <th>2011-02-04</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-04-15</th>\n",
       "      <th>2016-04-16</th>\n",
       "      <th>2016-04-17</th>\n",
       "      <th>2016-04-18</th>\n",
       "      <th>2016-04-19</th>\n",
       "      <th>2016-04-20</th>\n",
       "      <th>2016-04-21</th>\n",
       "      <th>2016-04-22</th>\n",
       "      <th>2016-04-23</th>\n",
       "      <th>2016-04-24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_512</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_514</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3049 rows × 1916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat_id      dept_id          item_id  2011-01-29  2011-01-30  \\\n",
       "0         FOODS      FOODS_1      FOODS_1_001           6           6   \n",
       "1         FOODS      FOODS_1      FOODS_1_002           4           5   \n",
       "2         FOODS      FOODS_1      FOODS_1_003          14           8   \n",
       "3         FOODS      FOODS_1      FOODS_1_004           0           0   \n",
       "4         FOODS      FOODS_1      FOODS_1_005          34          32   \n",
       "...         ...          ...              ...         ...         ...   \n",
       "3044  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_512           5           4   \n",
       "3045  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_513           0           0   \n",
       "3046  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_514           4           8   \n",
       "3047  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_515           0           0   \n",
       "3048  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_516           2           4   \n",
       "\n",
       "      2011-01-31  2011-02-01  2011-02-02  2011-02-03  2011-02-04  ...  \\\n",
       "0              4           6           7          18          10  ...   \n",
       "1              7           4           3           4           1  ...   \n",
       "2              3           6           3           8          13  ...   \n",
       "3              0           0           0           0           0  ...   \n",
       "4             13          20          10          21          18  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "3044           1           3           2           4           2  ...   \n",
       "3045           0           0           0           0           0  ...   \n",
       "3046           2           1           1           2           3  ...   \n",
       "3047           0           0           0           0           0  ...   \n",
       "3048           0           3           1           2           2  ...   \n",
       "\n",
       "      2016-04-15  2016-04-16  2016-04-17  2016-04-18  2016-04-19  2016-04-20  \\\n",
       "0              4           4          30           7           5           3   \n",
       "1              5           9           4           1           3           5   \n",
       "2              7           3           5           6           3           4   \n",
       "3              0           0           0           0           0           0   \n",
       "4             16          14          14          18          18          27   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3044           6           7           9          13          12           2   \n",
       "3045           9           3           3           3           2           4   \n",
       "3046           1           2           2           0           1           0   \n",
       "3047           1           3           2           0           0           1   \n",
       "3048           4           1           1           0           0           1   \n",
       "\n",
       "      2016-04-21  2016-04-22  2016-04-23  2016-04-24  \n",
       "0              6           2          16           6  \n",
       "1              5           3           3           1  \n",
       "2              4           3          11           5  \n",
       "3              0           0           0           0  \n",
       "4             12          15          38           9  \n",
       "...          ...         ...         ...         ...  \n",
       "3044           8           6          10           5  \n",
       "3045           6           7           4          11  \n",
       "3046           0           2           2           2  \n",
       "3047           1           1           5           1  \n",
       "3048           2           1           0           1  \n",
       "\n",
       "[3049 rows x 1916 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time related covariates: \n",
    "\n",
    "- Wehther it is weekend/not, we observed sales are high overweekend across three categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [d_to_date[d] for d in sales_train_validation.columns[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statrting date is 2011-01-29\n",
      "The statrting date is 2016-04-24\n"
     ]
    }
   ],
   "source": [
    "print(f'The statrting date is {date[0]}')\n",
    "print(f'The statrting date is {date[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given data is weekday.\n"
     ]
    }
   ],
   "source": [
    "d = datetime.strptime(date[2], '%Y-%m-%d')\n",
    "if d.weekday() > 4:\n",
    "    print ('Given date is weekend.')\n",
    "else:\n",
    "    print ('Given data is weekday.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913\n"
     ]
    }
   ],
   "source": [
    "weekend_binary = [1 if (datetime.strptime(d, '%Y-%m-%d')).weekday() > 4 else 0 for d in date]\n",
    "print(len(weekend_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 30490)\n"
     ]
    }
   ],
   "source": [
    "stv = sales_train_validation[sales_train_validation.columns[6:]]\n",
    "stv = stv.T\n",
    "print(stv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stv.sum(axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "hie_index = torch.arange(stv.shape[1])\n",
    "\n",
    "hie_index_2d = hie_index.expand(stv.shape[0], stv.shape[1])\n",
    "\n",
    "hie_index_3d = hie_index_2d.reshape(\n",
    "    hie_index_2d.shape[0], hie_index_2d.shape[-1], 1\n",
    ")\n",
    "\n",
    "print(hie_index_3d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913.0\n",
      "(1913, 30490, 1)\n",
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "stv_proportions = np.divide(stv.values, stv.sum(axis=1).values.reshape(-1,1))\n",
    "print(stv_proportions.sum(axis=1).sum())\n",
    "\n",
    "stv_proportions_3d = stv_proportions.reshape(stv_proportions.shape[0], stv_proportions.shape[1], 1)\n",
    "print(stv_proportions_3d.shape)\n",
    "\n",
    "proportions_tensor = torch.tensor(stv_proportions_3d)\n",
    "print(proportions_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n",
      "tensor([1])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weekend_binary_tensor = torch.tensor(weekend_binary).unsqueeze_(-1).unsqueeze_(-1)\n",
    "weekend_binary_tensor = weekend_binary_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], weekend_binary_tensor.shape[-1])\n",
    "print(weekend_binary_tensor.shape)\n",
    "print(weekend_binary_tensor[1,0])\n",
    "print(weekend_binary_tensor[2,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "parent_sales_tensor = torch.tensor(parent_sales).unsqueeze_(-1).unsqueeze_(-1)\n",
    "parent_sales_tensor = parent_sales_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], parent_sales_tensor.shape[-1])\n",
    "print(parent_sales_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 4])\n"
     ]
    }
   ],
   "source": [
    "data_3d = torch.cat((proportions_tensor, parent_sales_tensor,weekend_binary_tensor, hie_index_3d), -1)\n",
    "data_3d = data_3d.double()\n",
    "print(data_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1858, 56, 30490, 4])\n",
      "torch.Size([56, 30490, 4])\n",
      "data correctly processed to generate time-bacted tensor\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n",
      "Entering the training pipeline\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "# dimension about the dataset\n",
    "no_child = proportions_tensor.shape[1]\n",
    "History = 28\n",
    "Forward = 28\n",
    "\n",
    "number_observations = data_3d.shape[0] - (History + Forward) + 1\n",
    "\n",
    "data_3d_time_batched = torch.empty(\n",
    "    number_observations, History + Forward, data_3d.shape[1], data_3d.shape[2]\n",
    ")\n",
    "\n",
    "for i in range(number_observations):\n",
    "\n",
    "    data_3d_time_batched[i, :, :, :] = data_3d[i : i + History + Forward, :, :]\n",
    "\n",
    "print(data_3d_time_batched.shape)\n",
    "print(data_3d_time_batched[-1,:,:,:].shape)\n",
    "\n",
    "\n",
    "#if torch.equal(data_3d_time_batched[-1, -1, :, :].double(), data_3d[-1, :, :].double()):\n",
    "\n",
    "print(\"data correctly processed to generate time-bacted tensor\")\n",
    "\n",
    "input_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    History,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    data_3d_time_batched.shape[-1],\n",
    ")\n",
    "\n",
    "## We first use the recursive predicitng mechanism in LSTM, in the future we release more blocks that adapt to teacher-forcing/mixed training\n",
    "target_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    Forward,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    1\n",
    "    # data_3d_time_batched.shape[-1]\n",
    ")\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "\n",
    "print(\"Entering the training pipeline\")\n",
    "\n",
    "for i in range(data_3d_time_batched.shape[0]):\n",
    "\n",
    "    input_tensor[i] = data_3d_time_batched[i, :History, :, :]\n",
    "    target_2d = data_3d_time_batched[i, History:, :, 0]\n",
    "    target_tensor[i] = target_2d.reshape(\n",
    "        target_2d.shape[0], target_2d.shape[1], 1\n",
    "    )\n",
    "\n",
    "    # print(input_tensor.shape)\n",
    "    # print(target_tensor.shape)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "    # print(target_tensor[-1,0,:,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 12, got 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericliu/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/notebook/feature_generation.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=38'>39</a>\u001b[0m l_r \u001b[39m=\u001b[39m \u001b[39m0.00079\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=40'>41</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=41'>42</a>\u001b[0m p_model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=42'>43</a>\u001b[0m     input_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=43'>44</a>\u001b[0m     target_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=44'>45</a>\u001b[0m     n_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=45'>46</a>\u001b[0m     target_len,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=46'>47</a>\u001b[0m     batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=47'>48</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49ml_r,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=48'>49</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:425\u001b[0m, in \u001b[0;36mproportion_model.train\u001b[0;34m(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m cat((\u001b[39minput\u001b[39m, embedd_vector), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[39m# print(f\"with ENCODED hierachy, input batch diemsion is {input.shape}\")\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[39m## ------------ lstm encoder ---input: L, C, input_dim ---------- ##\u001b[39;00m\n\u001b[1;32m    422\u001b[0m encoder_ouput, (\n\u001b[1;32m    423\u001b[0m     encoder_hn,\n\u001b[1;32m    424\u001b[0m     encoder_cn,\n\u001b[0;32m--> 425\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_lstm\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m, h0, c0)\n\u001b[1;32m    426\u001b[0m encoder_cache \u001b[39m=\u001b[39m (encoder_hn, encoder_cn)\n\u001b[1;32m    427\u001b[0m \u001b[39m# print(f\"The encoder final hidden state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# print(f\"The encoder final cell state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[39m## ------------- lstm ddecoder --------L, C, input_dim ----------- ##\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:119\u001b[0m, in \u001b[0;36mencoder_lstm.forward\u001b[0;34m(self, x, h0, c0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h0, c0):\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m    : param x :                    input of shape (# in batch, seq_len, lstm_input_dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    :                              element in the sequence\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     encoder_ouptut, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m encoder_ouptut, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 759\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:684\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    680\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    683\u001b[0m                        ):\n\u001b[0;32m--> 684\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    685\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    686\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    687\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    688\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 12, got 11"
     ]
    }
   ],
   "source": [
    "###---------- dimension on the model hypter-parameters from the paper ------------ ######\n",
    "num_hts_embedd = no_child\n",
    "hts_embedd_dim = 8\n",
    "covariate_dim = 2 \n",
    "\n",
    "lstm_input_dim = 2 + covariate_dim + hts_embedd_dim\n",
    "lstm_hidden_dim = 48\n",
    "lstm_num_layer = 1\n",
    "lstm_output_dim = 64\n",
    "\n",
    "mha_embedd_dim = lstm_output_dim\n",
    "num_head = 4\n",
    "num_attention_layer = 1\n",
    "mha_output_dim = mha_embedd_dim\n",
    "residual_output_dim = mha_output_dim\n",
    "model_ouput_dim = 1\n",
    "\n",
    "# define the model object\n",
    "p_model = proportion_model(\n",
    "    num_hts_embedd,\n",
    "    hts_embedd_dim,  # ts embedding hyper pars\n",
    "    lstm_input_dim,\n",
    "    lstm_hidden_dim,\n",
    "    lstm_num_layer,\n",
    "    lstm_output_dim,  # lstm hyper pars\n",
    "    mha_embedd_dim,\n",
    "    num_head,\n",
    "    num_attention_layer,  # mha hyper pars\n",
    "    mha_output_dim,\n",
    "    residual_output_dim,  # skip connection hyper pars\n",
    "    model_ouput_dim,  # output later hyper pars\n",
    ")\n",
    "\n",
    "###---------- trainign parameters from the paper ------------ ######\n",
    "\n",
    "n_epochs = 50\n",
    "target_len = Forward\n",
    "batch_size = 4\n",
    "l_r = 0.00079\n",
    "\n",
    "# start training\n",
    "p_model.train(\n",
    "    input_tensor,\n",
    "    target_tensor,\n",
    "    n_epochs,\n",
    "    target_len,\n",
    "    batch_size,\n",
    "    learning_rate=l_r,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
