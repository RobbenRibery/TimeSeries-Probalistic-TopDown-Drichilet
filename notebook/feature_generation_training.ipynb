{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.insert(0, '../src/')\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "import torch \n",
    "\n",
    "\n",
    "import proption_model \n",
    "import hierachy_encoding \n",
    "import utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('../data/sales_train_validation.csv')\n",
    "sales_train_evaluation = pd.read_csv('../data/sales_train_evaluation.csv') \n",
    "calender = pd.read_csv('../data/calendar.csv') \n",
    "date_to_d = dict(zip(calender.date, calender.d)) \n",
    "d_to_date = dict(zip(calender.d, calender.date)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent nodes sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913,)\n"
     ]
    }
   ],
   "source": [
    "parent_sales = sales_train_validation[sales_train_validation.columns[6:]].sum(axis=0).values\n",
    "print(parent_sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hie EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
       "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
       "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
       "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "1       0       0       0       0       0  \n",
       "2       0       2       3       0       1  \n",
       "3       1       3       0       2       6  \n",
       "4       0       0       2       1       0  \n",
       "\n",
       "[5 rows x 1947 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30490, 1947)\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_evaluation.shape)\n",
    "print(sales_train_evaluation.columns[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_list = ['state_id','store_id','cat_id','dept_id','item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully encoded hierachy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CA</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CA_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WI</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">WI_3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD_2</th>\n",
       "      <th>HOUSEHOLD_2_512</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_513</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_514</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         id\n",
       "state_id store_id cat_id    dept_id     item_id            \n",
       "CA       CA_1     FOODS     FOODS_1     FOODS_1_001       1\n",
       "                                        FOODS_1_002       1\n",
       "                                        FOODS_1_003       1\n",
       "                                        FOODS_1_004       1\n",
       "                                        FOODS_1_005       1\n",
       "...                                                      ..\n",
       "WI       WI_3     HOUSEHOLD HOUSEHOLD_2 HOUSEHOLD_2_512   1\n",
       "                                        HOUSEHOLD_2_513   1\n",
       "                                        HOUSEHOLD_2_514   1\n",
       "                                        HOUSEHOLD_2_515   1\n",
       "                                        HOUSEHOLD_2_516   1\n",
       "\n",
       "[30490 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup = sales_train_evaluation.groupby(groupby_list[:]).count()[['id']]\n",
    "hierachy_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierachy_lookup.loc[('CA','CA_1','FOODS','FOODS_1')].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Partially encoded hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id\n",
       "cat_id dept_id item_id        \n",
       "FOODS  FOODS_1 FOODS_1_001  10\n",
       "               FOODS_1_002  10\n",
       "               FOODS_1_003  10\n",
       "               FOODS_1_004  10\n",
       "               FOODS_1_005  10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2 = sales_train_evaluation.groupby(groupby_list[2:]).count()[['id']]\n",
    "hierachy_lookup_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">FOODS_1</th>\n",
       "      <th>FOODS_1_001</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_002</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_003</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_004</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_005</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HOUSEHOLD_2</th>\n",
       "      <th>HOUSEHOLD_2_512</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_513</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_514</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_515</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3049 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id\n",
       "cat_id    dept_id     item_id            \n",
       "FOODS     FOODS_1     FOODS_1_001      10\n",
       "                      FOODS_1_002      10\n",
       "                      FOODS_1_003      10\n",
       "                      FOODS_1_004      10\n",
       "                      FOODS_1_005      10\n",
       "...                                    ..\n",
       "HOUSEHOLD HOUSEHOLD_2 HOUSEHOLD_2_512  10\n",
       "                      HOUSEHOLD_2_513  10\n",
       "                      HOUSEHOLD_2_514  10\n",
       "                      HOUSEHOLD_2_515  10\n",
       "                      HOUSEHOLD_2_516  10\n",
       "\n",
       "[3049 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TS encoding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierachy_lookup_2 = hierachy_lookup_2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOODS_3        823\n",
       "HOUSEHOLD_1    532\n",
       "HOUSEHOLD_2    515\n",
       "HOBBIES_1      416\n",
       "FOODS_2        398\n",
       "FOODS_1        216\n",
       "HOBBIES_2      149\n",
       "Name: dept_id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_lookup_2.dept_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FOODS': 0, 'HOBBIES': 1, 'HOUSEHOLD': 2}\n",
      "{'FOODS_1': 3, 'FOODS_2': 4, 'FOODS_3': 5, 'HOBBIES_1': 6, 'HOBBIES_2': 7, 'HOUSEHOLD_1': 8, 'HOUSEHOLD_2': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hierachy_with_encoded_columns = hierachy_encoding.hie_encoder(hierachy_lookup_2, ['cat_id','dept_id','item_id'])\n",
    "\n",
    "root_to_index = {'root':0}\n",
    "\n",
    "cat_to_dix = dict(zip(hierachy_with_encoded_columns.cat_id,hierachy_with_encoded_columns.cat_id_))\n",
    "print(cat_to_dix)\n",
    "\n",
    "\n",
    "dep_to_dix = dict(zip(hierachy_with_encoded_columns.dept_id,hierachy_with_encoded_columns.dept_id_))\n",
    "print(dep_to_dix)\n",
    "\n",
    "item_to_dix = dict(zip(hierachy_with_encoded_columns.item_id,hierachy_with_encoded_columns.item_id_))\n",
    "#print(item_to_dix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060\n"
     ]
    }
   ],
   "source": [
    "ts_to_index = {}\n",
    "for dic in [root_to_index, cat_to_dix, dep_to_dix, item_to_dix]:\n",
    "    ts_to_index.update(dic)\n",
    "print(len(ts_to_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3059\n"
     ]
    }
   ],
   "source": [
    "inde_to_ts = dict(zip(ts_to_index.values(), ts_to_index.keys()))\n",
    "print(len(inde_to_ts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'FOODS_1': 0,\n",
       "             'FOODS_2': 0,\n",
       "             'FOODS_3': 0,\n",
       "             'HOBBIES_1': 1,\n",
       "             'HOBBIES_2': 1,\n",
       "             'HOUSEHOLD_1': 2,\n",
       "             'HOUSEHOLD_2': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_parent_index = hierachy_encoding.get_parent_index(dep_to_dix, cat_to_dix)\n",
    "dep_parent_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_parent_index = hierachy_encoding.get_parent_index(item_to_dix, dep_to_dix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- Need to constrcut a grpah here, proceeed to next step first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'root': [0, 1, 2]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierachy_encoding.get_children_index(cat_to_dix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick a particular familry to construct one training data points \n",
    "    - Parent node - 0 \n",
    "    - Children node - 1, 2, 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect parent sales \n",
    "yp = sales_train_validation.sum(axis=0)[6:].values.reshape(-1,1)# np array \n",
    "yp = yp.T \n",
    "print(yp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOODS</th>\n",
       "      <td>23178</td>\n",
       "      <td>22758</td>\n",
       "      <td>17174</td>\n",
       "      <td>18878</td>\n",
       "      <td>14603</td>\n",
       "      <td>22093</td>\n",
       "      <td>20490</td>\n",
       "      <td>27751</td>\n",
       "      <td>24862</td>\n",
       "      <td>18901</td>\n",
       "      <td>...</td>\n",
       "      <td>28682</td>\n",
       "      <td>32007</td>\n",
       "      <td>34497</td>\n",
       "      <td>26151</td>\n",
       "      <td>24948</td>\n",
       "      <td>23632</td>\n",
       "      <td>23317</td>\n",
       "      <td>26704</td>\n",
       "      <td>31927</td>\n",
       "      <td>32654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES</th>\n",
       "      <td>3764</td>\n",
       "      <td>3357</td>\n",
       "      <td>2682</td>\n",
       "      <td>2669</td>\n",
       "      <td>1814</td>\n",
       "      <td>3220</td>\n",
       "      <td>2944</td>\n",
       "      <td>3986</td>\n",
       "      <td>2899</td>\n",
       "      <td>2615</td>\n",
       "      <td>...</td>\n",
       "      <td>3786</td>\n",
       "      <td>4634</td>\n",
       "      <td>4820</td>\n",
       "      <td>3323</td>\n",
       "      <td>3787</td>\n",
       "      <td>3472</td>\n",
       "      <td>3353</td>\n",
       "      <td>4085</td>\n",
       "      <td>4787</td>\n",
       "      <td>4683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD</th>\n",
       "      <td>5689</td>\n",
       "      <td>5634</td>\n",
       "      <td>3927</td>\n",
       "      <td>3865</td>\n",
       "      <td>2729</td>\n",
       "      <td>3898</td>\n",
       "      <td>4576</td>\n",
       "      <td>6195</td>\n",
       "      <td>4975</td>\n",
       "      <td>4056</td>\n",
       "      <td>...</td>\n",
       "      <td>9321</td>\n",
       "      <td>11721</td>\n",
       "      <td>12323</td>\n",
       "      <td>8585</td>\n",
       "      <td>8835</td>\n",
       "      <td>8239</td>\n",
       "      <td>8363</td>\n",
       "      <td>9728</td>\n",
       "      <td>12248</td>\n",
       "      <td>12458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             d_1    d_2    d_3    d_4    d_5    d_6    d_7    d_8    d_9  \\\n",
       "cat_id                                                                     \n",
       "FOODS      23178  22758  17174  18878  14603  22093  20490  27751  24862   \n",
       "HOBBIES     3764   3357   2682   2669   1814   3220   2944   3986   2899   \n",
       "HOUSEHOLD   5689   5634   3927   3865   2729   3898   4576   6195   4975   \n",
       "\n",
       "            d_10  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  \\\n",
       "cat_id            ...                                                           \n",
       "FOODS      18901  ...   28682   32007   34497   26151   24948   23632   23317   \n",
       "HOBBIES     2615  ...    3786    4634    4820    3323    3787    3472    3353   \n",
       "HOUSEHOLD   4056  ...    9321   11721   12323    8585    8835    8239    8363   \n",
       "\n",
       "           d_1911  d_1912  d_1913  \n",
       "cat_id                             \n",
       "FOODS       26704   31927   32654  \n",
       "HOBBIES      4085    4787    4683  \n",
       "HOUSEHOLD    9728   12248   12458  \n",
       "\n",
       "[3 rows x 1913 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_validation.groupby('cat_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect the proportinos \n",
    "ac = sales_train_validation.groupby('cat_id').sum().values/yp\n",
    "print(ac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913)\n"
     ]
    }
   ],
   "source": [
    "# collect the embedding layer input \n",
    "ec = np.array(hierachy_encoding.get_children_index(cat_to_dix)['root']).reshape(-1,1)\n",
    "ec = np.repeat(ec, 1913, axis=1)\n",
    "print(ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913, 3)\n",
      "0\n",
      "(1913, 3)\n",
      "1\n",
      "(1913, 3)\n",
      "2\n",
      "(1913, 3)\n"
     ]
    }
   ],
   "source": [
    "if ac.shape[0] == ec.shape[0]: \n",
    "\n",
    "    input = np.empty(\n",
    "        \n",
    "        (ac.shape[0], ac.shape[1], 3), \n",
    "    \n",
    "    )\n",
    "    print(input.shape)\n",
    "\n",
    "    for c in range(input.shape[0]): \n",
    "        print(c)\n",
    "        # print(yp.T.shape)\n",
    "        # print(ac[c].reshape(-1,1).shape)\n",
    "        # print(ec[c].reshape(-1,1).shape)\n",
    "        input[c] = np.concatenate(\n",
    "            [\n",
    "                ac[c].reshape(-1,1), \n",
    "                yp.T, \n",
    "                ## ---- PLACE HOLDER FOR COVARIATES X ---- ## \n",
    "                ## ---- PLACE HOLDER FOR COVARIATES X ---- ## \n",
    "                ec[c].reshape(-1,1),\n",
    "            ], \n",
    "            axis = 1 \n",
    "        )\n",
    "        print(input[c].shape)    \n",
    "else: \n",
    "    raise \"size of children in embedding does not agree with size of the children in proportions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1913, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Time batched input --------\n",
      "(1893, 3, 21, 3)\n",
      "-------- X, y split ------------\n",
      "X input shape is (1893, 3, 14, 3)\n",
      "y input shape is (1893, 3, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "## time batching \n",
    "# dimension about the dataset\n",
    "print('------- Time batched input --------')\n",
    "History = 14\n",
    "Forward = 7\n",
    "\n",
    "number_observations = input.shape[1] - (History + Forward) + 1\n",
    "\n",
    "input_time_batched = np.empty(\n",
    "    (number_observations,input.shape[0], History + Forward, input.shape[-1])\n",
    ")\n",
    "\n",
    "for i in range(number_observations):\n",
    "\n",
    "    input_time_batched[i] = np.array(input[:, i:i + History + Forward, :])\n",
    "\n",
    "print(input_time_batched.shape)\n",
    "# print(input_time_batched[0][0])\n",
    "\n",
    "print(\"-------- X, y split ------------\")\n",
    "input_array = np.empty((\n",
    "    number_observations,\n",
    "    input.shape[0],\n",
    "    History,\n",
    "    input.shape[-1])\n",
    ")\n",
    "\n",
    "target_array = np.empty((\n",
    "    number_observations,\n",
    "    input.shape[0],\n",
    "    Forward,\n",
    "    1)\n",
    ")\n",
    "\n",
    "# print(input_tensor.shape)\n",
    "# print(target_tensor.shape)\n",
    "\n",
    "for i in range(input_time_batched.shape[0]):\n",
    "\n",
    "    input_array[i] = input_time_batched[i, :, :History, :]\n",
    "\n",
    "    #print(input_array[i,0,-1,0])\n",
    "\n",
    "    target_2d = input_time_batched[i, :, History:, 0]\n",
    "    \n",
    "    target_array[i] = target_2d.reshape(\n",
    "        target_2d.shape[0], target_2d.shape[1], 1\n",
    "    )\n",
    "\n",
    "    #print(target_array[i,0,0,0])\n",
    "    #print()\n",
    "\n",
    "print(f\"X input shape is {input_array.shape}\")\n",
    "print(f\"y input shape is {target_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- blue box X shape (1893, 2, 14, 3)\n",
    "- green box X shape (1893, 2, 14, 3)\n",
    "- y target is the proportal of ever single child \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.10306151e-01, 3.26310000e+04, 0.00000000e+00],\n",
       "       [7.16809978e-01, 3.17490000e+04, 0.00000000e+00],\n",
       "       [7.22112433e-01, 2.37830000e+04, 0.00000000e+00],\n",
       "       [7.42877381e-01, 2.54120000e+04, 0.00000000e+00],\n",
       "       [7.62718061e-01, 1.91460000e+04, 0.00000000e+00],\n",
       "       [7.56324672e-01, 2.92110000e+04, 0.00000000e+00],\n",
       "       [7.31524456e-01, 2.80100000e+04, 0.00000000e+00],\n",
       "       [7.31598650e-01, 3.79320000e+04, 0.00000000e+00],\n",
       "       [7.59469697e-01, 3.27360000e+04, 0.00000000e+00],\n",
       "       [7.39128735e-01, 2.55720000e+04, 0.00000000e+00],\n",
       "       [7.35252048e-01, 2.30710000e+04, 0.00000000e+00],\n",
       "       [7.46259194e-01, 2.36580000e+04, 0.00000000e+00],\n",
       "       [7.29920862e-01, 2.37560000e+04, 0.00000000e+00],\n",
       "       [7.19909246e-01, 2.64450000e+04, 0.00000000e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.16809978e-01, 3.17490000e+04, 0.00000000e+00],\n",
       "       [7.22112433e-01, 2.37830000e+04, 0.00000000e+00],\n",
       "       [7.42877381e-01, 2.54120000e+04, 0.00000000e+00],\n",
       "       [7.62718061e-01, 1.91460000e+04, 0.00000000e+00],\n",
       "       [7.56324672e-01, 2.92110000e+04, 0.00000000e+00],\n",
       "       [7.31524456e-01, 2.80100000e+04, 0.00000000e+00],\n",
       "       [7.31598650e-01, 3.79320000e+04, 0.00000000e+00],\n",
       "       [7.59469697e-01, 3.27360000e+04, 0.00000000e+00],\n",
       "       [7.39128735e-01, 2.55720000e+04, 0.00000000e+00],\n",
       "       [7.35252048e-01, 2.30710000e+04, 0.00000000e+00],\n",
       "       [7.46259194e-01, 2.36580000e+04, 0.00000000e+00],\n",
       "       [7.29920862e-01, 2.37560000e+04, 0.00000000e+00],\n",
       "       [7.19909246e-01, 2.64450000e+04, 0.00000000e+00],\n",
       "       [7.23078690e-01, 3.48330000e+04, 0.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array[1,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72307869],\n",
       "       [0.73271028],\n",
       "       [0.73449826],\n",
       "       [0.7239302 ],\n",
       "       [0.71589796],\n",
       "       [0.70331726],\n",
       "       [0.69954892]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73271028],\n",
       "       [0.73449826],\n",
       "       [0.7239302 ],\n",
       "       [0.71589796],\n",
       "       [0.70331726],\n",
       "       [0.69954892],\n",
       "       [0.66073401]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array[1,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.10306151e-01, 3.26310000e+04, 0.00000000e+00],\n",
       "       [1.15350434e-01, 3.26310000e+04, 1.00000000e+00],\n",
       "       [1.74343416e-01, 3.26310000e+04, 2.00000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array[0,:,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 474 batches during the training process of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4378, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4402, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4385, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4351, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7702, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7121, grad_fn=<CopyBackwards>)\n",
      "tensor(3.8525, grad_fn=<CopyBackwards>)\n",
      "tensor(3.8812, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7819, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7478, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7607, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7582, grad_fn=<CopyBackwards>)\n",
      "tensor(6.2603, grad_fn=<CopyBackwards>)\n",
      "tensor(6.3581, grad_fn=<CopyBackwards>)\n",
      "tensor(6.2389, grad_fn=<CopyBackwards>)\n",
      "tensor(6.2273, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9255, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9087, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9066, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9271, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9728, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9708, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0009, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0585, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4148, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4512, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4776, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4702, grad_fn=<CopyBackwards>)\n",
      "tensor(6.0895, grad_fn=<CopyBackwards>)\n",
      "tensor(6.5472, grad_fn=<CopyBackwards>)\n",
      "tensor(6.4848, grad_fn=<CopyBackwards>)\n",
      "tensor(6.1609, grad_fn=<CopyBackwards>)\n",
      "tensor(17.5928, grad_fn=<CopyBackwards>)\n",
      "tensor(17.4277, grad_fn=<CopyBackwards>)\n",
      "tensor(16.6091, grad_fn=<CopyBackwards>)\n",
      "tensor(16.0613, grad_fn=<CopyBackwards>)\n",
      "tensor(709.7657, grad_fn=<CopyBackwards>)\n",
      "tensor(643.6757, grad_fn=<CopyBackwards>)\n",
      "tensor(599.4753, grad_fn=<CopyBackwards>)\n",
      "tensor(602.8105, grad_fn=<CopyBackwards>)\n",
      "tensor(6.9146, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8732, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8828, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8827, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4955, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4967, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4984, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4933, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4962, grad_fn=<CopyBackwards>)\n",
      "tensor(1.5011, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4850, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4948, grad_fn=<CopyBackwards>)\n",
      "tensor(1.0658, grad_fn=<CopyBackwards>)\n",
      "tensor(1.0487, grad_fn=<CopyBackwards>)\n",
      "tensor(1.0657, grad_fn=<CopyBackwards>)\n",
      "tensor(1.0531, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8031, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8233, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8078, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8330, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6927, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6765, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6988, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7040, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6553, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6712, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6789, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6805, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7360, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7454, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7455, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7531, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9281, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9266, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9334, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9318, grad_fn=<CopyBackwards>)\n",
      "tensor(1.2887, grad_fn=<CopyBackwards>)\n",
      "tensor(1.2933, grad_fn=<CopyBackwards>)\n",
      "tensor(1.2927, grad_fn=<CopyBackwards>)\n",
      "tensor(1.3155, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9726, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9774, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0499, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0808, grad_fn=<CopyBackwards>)\n",
      "tensor(3.3626, grad_fn=<CopyBackwards>)\n",
      "tensor(3.5799, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7053, grad_fn=<CopyBackwards>)\n",
      "tensor(3.5948, grad_fn=<CopyBackwards>)\n",
      "tensor(7.1343, grad_fn=<CopyBackwards>)\n",
      "tensor(7.5473, grad_fn=<CopyBackwards>)\n",
      "tensor(7.3155, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8771, grad_fn=<CopyBackwards>)\n",
      "tensor(18.1768, grad_fn=<CopyBackwards>)\n",
      "tensor(17.0869, grad_fn=<CopyBackwards>)\n",
      "tensor(15.5245, grad_fn=<CopyBackwards>)\n",
      "tensor(14.2974, grad_fn=<CopyBackwards>)\n",
      "tensor(23.2210, grad_fn=<CopyBackwards>)\n",
      "tensor(20.6450, grad_fn=<CopyBackwards>)\n",
      "tensor(18.7622, grad_fn=<CopyBackwards>)\n",
      "tensor(17.9793, grad_fn=<CopyBackwards>)\n",
      "tensor(9.7063, grad_fn=<CopyBackwards>)\n",
      "tensor(9.0553, grad_fn=<CopyBackwards>)\n",
      "tensor(8.8135, grad_fn=<CopyBackwards>)\n",
      "tensor(9.1093, grad_fn=<CopyBackwards>)\n",
      "tensor(5.6874, grad_fn=<CopyBackwards>)\n",
      "tensor(5.6048, grad_fn=<CopyBackwards>)\n",
      "tensor(5.7273, grad_fn=<CopyBackwards>)\n",
      "tensor(6.0519, grad_fn=<CopyBackwards>)\n",
      "tensor(6.5069, grad_fn=<CopyBackwards>)\n",
      "tensor(6.6246, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8638, grad_fn=<CopyBackwards>)\n",
      "tensor(7.1257, grad_fn=<CopyBackwards>)\n",
      "tensor(14.5555, grad_fn=<CopyBackwards>)\n",
      "tensor(15.4716, grad_fn=<CopyBackwards>)\n",
      "tensor(16.0400, grad_fn=<CopyBackwards>)\n",
      "tensor(15.1923, grad_fn=<CopyBackwards>)\n",
      "tensor(16.7495, grad_fn=<CopyBackwards>)\n",
      "tensor(17.3134, grad_fn=<CopyBackwards>)\n",
      "tensor(16.5800, grad_fn=<CopyBackwards>)\n",
      "tensor(15.9970, grad_fn=<CopyBackwards>)\n",
      "tensor(12.0122, grad_fn=<CopyBackwards>)\n",
      "tensor(11.7797, grad_fn=<CopyBackwards>)\n",
      "tensor(11.4851, grad_fn=<CopyBackwards>)\n",
      "tensor(11.2352, grad_fn=<CopyBackwards>)\n",
      "tensor(17.0754, grad_fn=<CopyBackwards>)\n",
      "tensor(16.7668, grad_fn=<CopyBackwards>)\n",
      "tensor(16.4665, grad_fn=<CopyBackwards>)\n",
      "tensor(16.2632, grad_fn=<CopyBackwards>)\n",
      "tensor(26.3339, grad_fn=<CopyBackwards>)\n",
      "tensor(25.5112, grad_fn=<CopyBackwards>)\n",
      "tensor(25.0356, grad_fn=<CopyBackwards>)\n",
      "tensor(25.3403, grad_fn=<CopyBackwards>)\n",
      "tensor(59.0353, grad_fn=<CopyBackwards>)\n",
      "tensor(58.0351, grad_fn=<CopyBackwards>)\n",
      "tensor(58.2859, grad_fn=<CopyBackwards>)\n",
      "tensor(59.9492, grad_fn=<CopyBackwards>)\n",
      "tensor(1300.2461, grad_fn=<CopyBackwards>)\n",
      "tensor(1341.9603, grad_fn=<CopyBackwards>)\n",
      "tensor(1603.4767, grad_fn=<CopyBackwards>)\n",
      "tensor(1726.2148, grad_fn=<CopyBackwards>)\n",
      "tensor(3.3247, grad_fn=<CopyBackwards>)\n",
      "tensor(3.1118, grad_fn=<CopyBackwards>)\n",
      "tensor(3.0946, grad_fn=<CopyBackwards>)\n",
      "tensor(3.3605, grad_fn=<CopyBackwards>)\n",
      "tensor(2.6655, grad_fn=<CopyBackwards>)\n",
      "tensor(2.6623, grad_fn=<CopyBackwards>)\n",
      "tensor(2.7614, grad_fn=<CopyBackwards>)\n",
      "tensor(2.7966, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2189, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2504, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2609, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2635, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7948, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7815, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7816, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7875, grad_fn=<CopyBackwards>)\n",
      "tensor(4.1150, grad_fn=<CopyBackwards>)\n",
      "tensor(4.1009, grad_fn=<CopyBackwards>)\n",
      "tensor(4.1255, grad_fn=<CopyBackwards>)\n",
      "tensor(4.3095, grad_fn=<CopyBackwards>)\n",
      "tensor(4.3570, grad_fn=<CopyBackwards>)\n",
      "tensor(4.4199, grad_fn=<CopyBackwards>)\n",
      "tensor(4.9685, grad_fn=<CopyBackwards>)\n",
      "tensor(5.5802, grad_fn=<CopyBackwards>)\n",
      "tensor(5.1610, grad_fn=<CopyBackwards>)\n",
      "tensor(5.7415, grad_fn=<CopyBackwards>)\n",
      "tensor(5.6611, grad_fn=<CopyBackwards>)\n",
      "tensor(5.4310, grad_fn=<CopyBackwards>)\n",
      "tensor(8.1724, grad_fn=<CopyBackwards>)\n",
      "tensor(7.8051, grad_fn=<CopyBackwards>)\n",
      "tensor(7.2283, grad_fn=<CopyBackwards>)\n",
      "tensor(7.3119, grad_fn=<CopyBackwards>)\n",
      "tensor(13.0491, grad_fn=<CopyBackwards>)\n",
      "tensor(12.0391, grad_fn=<CopyBackwards>)\n",
      "tensor(10.4380, grad_fn=<CopyBackwards>)\n",
      "tensor(10.3495, grad_fn=<CopyBackwards>)\n",
      "tensor(13.8316, grad_fn=<CopyBackwards>)\n",
      "tensor(10.8478, grad_fn=<CopyBackwards>)\n",
      "tensor(10.7202, grad_fn=<CopyBackwards>)\n",
      "tensor(10.9501, grad_fn=<CopyBackwards>)\n",
      "tensor(5.9081, grad_fn=<CopyBackwards>)\n",
      "tensor(6.0231, grad_fn=<CopyBackwards>)\n",
      "tensor(6.1689, grad_fn=<CopyBackwards>)\n",
      "tensor(6.4891, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7092, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7863, grad_fn=<CopyBackwards>)\n",
      "tensor(3.8964, grad_fn=<CopyBackwards>)\n",
      "tensor(4.0261, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2347, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2441, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2398, grad_fn=<CopyBackwards>)\n",
      "tensor(3.2142, grad_fn=<CopyBackwards>)\n",
      "tensor(3.9404, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7897, grad_fn=<CopyBackwards>)\n",
      "tensor(3.7954, grad_fn=<CopyBackwards>)\n",
      "tensor(3.5925, grad_fn=<CopyBackwards>)\n",
      "tensor(5.6171, grad_fn=<CopyBackwards>)\n",
      "tensor(5.8585, grad_fn=<CopyBackwards>)\n",
      "tensor(5.5365, grad_fn=<CopyBackwards>)\n",
      "tensor(5.5576, grad_fn=<CopyBackwards>)\n",
      "tensor(7.6902, grad_fn=<CopyBackwards>)\n",
      "tensor(7.3618, grad_fn=<CopyBackwards>)\n",
      "tensor(7.7548, grad_fn=<CopyBackwards>)\n",
      "tensor(8.1454, grad_fn=<CopyBackwards>)\n",
      "tensor(14.3517, grad_fn=<CopyBackwards>)\n",
      "tensor(13.1748, grad_fn=<CopyBackwards>)\n",
      "tensor(13.5269, grad_fn=<CopyBackwards>)\n",
      "tensor(14.0455, grad_fn=<CopyBackwards>)\n",
      "tensor(9.3861, grad_fn=<CopyBackwards>)\n",
      "tensor(11.1775, grad_fn=<CopyBackwards>)\n",
      "tensor(13.1280, grad_fn=<CopyBackwards>)\n",
      "tensor(13.5954, grad_fn=<CopyBackwards>)\n",
      "tensor(38.8537, grad_fn=<CopyBackwards>)\n",
      "tensor(35.4443, grad_fn=<CopyBackwards>)\n",
      "tensor(34.7147, grad_fn=<CopyBackwards>)\n",
      "tensor(40.6417, grad_fn=<CopyBackwards>)\n",
      "tensor(54.3187, grad_fn=<CopyBackwards>)\n",
      "tensor(53.0863, grad_fn=<CopyBackwards>)\n",
      "tensor(62.8669, grad_fn=<CopyBackwards>)\n",
      "tensor(116.7923, grad_fn=<CopyBackwards>)\n",
      "tensor(12.8650, grad_fn=<CopyBackwards>)\n",
      "tensor(13.9842, grad_fn=<CopyBackwards>)\n",
      "tensor(18.1216, grad_fn=<CopyBackwards>)\n",
      "tensor(17.7424, grad_fn=<CopyBackwards>)\n",
      "tensor(2.1148, grad_fn=<CopyBackwards>)\n",
      "tensor(1.2471, grad_fn=<CopyBackwards>)\n",
      "tensor(1.3707, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2086, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2513, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2219, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4071, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4648, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2939, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2080, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2670, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2503, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4366, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2850, grad_fn=<CopyBackwards>)\n",
      "tensor(0.1389, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2251, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3234, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3706, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4468, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4874, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4465, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4875, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5123, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5667, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4785, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4897, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5944, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3691, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5285, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8619, grad_fn=<CopyBackwards>)\n",
      "tensor(1.1193, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9827, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7943, grad_fn=<CopyBackwards>)\n",
      "tensor(1.7653, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8814, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4591, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9061, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7808, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5111, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7185, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7138, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5681, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8917, grad_fn=<CopyBackwards>)\n",
      "tensor(0.8045, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7408, grad_fn=<CopyBackwards>)\n",
      "tensor(1.2447, grad_fn=<CopyBackwards>)\n",
      "tensor(1.1041, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0746, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9520, grad_fn=<CopyBackwards>)\n",
      "tensor(1.6563, grad_fn=<CopyBackwards>)\n",
      "tensor(3.0903, grad_fn=<CopyBackwards>)\n",
      "tensor(2.7665, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0128, grad_fn=<CopyBackwards>)\n",
      "tensor(3.5117, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0941, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4224, grad_fn=<CopyBackwards>)\n",
      "tensor(3.1185, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5990, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7863, grad_fn=<CopyBackwards>)\n",
      "tensor(1.1222, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5316, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5819, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9382, grad_fn=<CopyBackwards>)\n",
      "tensor(1.3605, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4244, grad_fn=<CopyBackwards>)\n",
      "tensor(1.8438, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4941, grad_fn=<CopyBackwards>)\n",
      "tensor(3.0494, grad_fn=<CopyBackwards>)\n",
      "tensor(3.8930, grad_fn=<CopyBackwards>)\n",
      "tensor(4.9848, grad_fn=<CopyBackwards>)\n",
      "tensor(6.1137, grad_fn=<CopyBackwards>)\n",
      "tensor(6.3615, grad_fn=<CopyBackwards>)\n",
      "tensor(3.3605, grad_fn=<CopyBackwards>)\n",
      "tensor(4.0811, grad_fn=<CopyBackwards>)\n",
      "tensor(4.4254, grad_fn=<CopyBackwards>)\n",
      "tensor(10.8408, grad_fn=<CopyBackwards>)\n",
      "tensor(6.1400, grad_fn=<CopyBackwards>)\n",
      "tensor(6.9259, grad_fn=<CopyBackwards>)\n",
      "tensor(18.8690, grad_fn=<CopyBackwards>)\n",
      "tensor(14.8908, grad_fn=<CopyBackwards>)\n",
      "tensor(18.8844, grad_fn=<CopyBackwards>)\n",
      "tensor(59.8255, grad_fn=<CopyBackwards>)\n",
      "tensor(51.0010, grad_fn=<CopyBackwards>)\n",
      "tensor(39.6875, grad_fn=<CopyBackwards>)\n",
      "tensor(18.2024, grad_fn=<CopyBackwards>)\n",
      "tensor(14.1090, grad_fn=<CopyBackwards>)\n",
      "tensor(10.7371, grad_fn=<CopyBackwards>)\n",
      "tensor(9.1699, grad_fn=<CopyBackwards>)\n",
      "tensor(10.5165, grad_fn=<CopyBackwards>)\n",
      "tensor(8.5461, grad_fn=<CopyBackwards>)\n",
      "tensor(8.7859, grad_fn=<CopyBackwards>)\n",
      "tensor(24.8748, grad_fn=<CopyBackwards>)\n",
      "tensor(23.8464, grad_fn=<CopyBackwards>)\n",
      "tensor(27.0702, grad_fn=<CopyBackwards>)\n",
      "tensor(71.0121, grad_fn=<CopyBackwards>)\n",
      "tensor(29.8285, grad_fn=<CopyBackwards>)\n",
      "tensor(4.7254, grad_fn=<CopyBackwards>)\n",
      "tensor(10.0566, grad_fn=<CopyBackwards>)\n",
      "tensor(5.7091, grad_fn=<CopyBackwards>)\n",
      "tensor(5.5675, grad_fn=<CopyBackwards>)\n",
      "tensor(11.3774, grad_fn=<CopyBackwards>)\n",
      "tensor(6.6366, grad_fn=<CopyBackwards>)\n",
      "tensor(6.4740, grad_fn=<CopyBackwards>)\n",
      "tensor(7.3656, grad_fn=<CopyBackwards>)\n",
      "tensor(24.4334, grad_fn=<CopyBackwards>)\n",
      "tensor(22.8274, grad_fn=<CopyBackwards>)\n",
      "tensor(28.7904, grad_fn=<CopyBackwards>)\n",
      "tensor(26.1397, grad_fn=<CopyBackwards>)\n",
      "tensor(9.4819, grad_fn=<CopyBackwards>)\n",
      "tensor(10.1097, grad_fn=<CopyBackwards>)\n",
      "tensor(6.1270, grad_fn=<CopyBackwards>)\n",
      "tensor(8.6097, grad_fn=<CopyBackwards>)\n",
      "tensor(13.4303, grad_fn=<CopyBackwards>)\n",
      "tensor(7.9807, grad_fn=<CopyBackwards>)\n",
      "tensor(10.8439, grad_fn=<CopyBackwards>)\n",
      "tensor(14.6630, grad_fn=<CopyBackwards>)\n",
      "tensor(44.9823, grad_fn=<CopyBackwards>)\n",
      "tensor(48.5953, grad_fn=<CopyBackwards>)\n",
      "tensor(66.1064, grad_fn=<CopyBackwards>)\n",
      "tensor(47.0727, grad_fn=<CopyBackwards>)\n",
      "tensor(247.3410, grad_fn=<CopyBackwards>)\n",
      "tensor(349.8331, grad_fn=<CopyBackwards>)\n",
      "tensor(202.0666, grad_fn=<CopyBackwards>)\n",
      "tensor(184.8564, grad_fn=<CopyBackwards>)\n",
      "tensor(71.7783, grad_fn=<CopyBackwards>)\n",
      "tensor(50.0466, grad_fn=<CopyBackwards>)\n",
      "tensor(50.3862, grad_fn=<CopyBackwards>)\n",
      "tensor(50.6836, grad_fn=<CopyBackwards>)\n",
      "tensor(16.7603, grad_fn=<CopyBackwards>)\n",
      "tensor(17.7153, grad_fn=<CopyBackwards>)\n",
      "tensor(18.7437, grad_fn=<CopyBackwards>)\n",
      "tensor(29.4730, grad_fn=<CopyBackwards>)\n",
      "tensor(12.3525, grad_fn=<CopyBackwards>)\n",
      "tensor(12.5591, grad_fn=<CopyBackwards>)\n",
      "tensor(18.6287, grad_fn=<CopyBackwards>)\n",
      "tensor(15.1172, grad_fn=<CopyBackwards>)\n",
      "tensor(13.3923, grad_fn=<CopyBackwards>)\n",
      "tensor(17.0679, grad_fn=<CopyBackwards>)\n",
      "tensor(13.9130, grad_fn=<CopyBackwards>)\n",
      "tensor(10.1858, grad_fn=<CopyBackwards>)\n",
      "tensor(23.5475, grad_fn=<CopyBackwards>)\n",
      "tensor(19.4197, grad_fn=<CopyBackwards>)\n",
      "tensor(14.7269, grad_fn=<CopyBackwards>)\n",
      "tensor(16.7114, grad_fn=<CopyBackwards>)\n",
      "tensor(47.6182, grad_fn=<CopyBackwards>)\n",
      "tensor(39.8350, grad_fn=<CopyBackwards>)\n",
      "tensor(29.5650, grad_fn=<CopyBackwards>)\n",
      "tensor(25.8260, grad_fn=<CopyBackwards>)\n",
      "tensor(61.8077, grad_fn=<CopyBackwards>)\n",
      "tensor(32.4785, grad_fn=<CopyBackwards>)\n",
      "tensor(26.8866, grad_fn=<CopyBackwards>)\n",
      "tensor(26.2619, grad_fn=<CopyBackwards>)\n",
      "tensor(26.7441, grad_fn=<CopyBackwards>)\n",
      "tensor(22.5053, grad_fn=<CopyBackwards>)\n",
      "tensor(21.5286, grad_fn=<CopyBackwards>)\n",
      "tensor(22.6707, grad_fn=<CopyBackwards>)\n",
      "tensor(26.3194, grad_fn=<CopyBackwards>)\n",
      "tensor(24.2646, grad_fn=<CopyBackwards>)\n",
      "tensor(24.5469, grad_fn=<CopyBackwards>)\n",
      "tensor(30.5789, grad_fn=<CopyBackwards>)\n",
      "tensor(39.1522, grad_fn=<CopyBackwards>)\n",
      "tensor(38.2337, grad_fn=<CopyBackwards>)\n",
      "tensor(46.5208, grad_fn=<CopyBackwards>)\n",
      "tensor(45.6014, grad_fn=<CopyBackwards>)\n",
      "tensor(38.8942, grad_fn=<CopyBackwards>)\n",
      "tensor(39.6762, grad_fn=<CopyBackwards>)\n",
      "tensor(35.6859, grad_fn=<CopyBackwards>)\n",
      "tensor(35.0855, grad_fn=<CopyBackwards>)\n",
      "tensor(47.5551, grad_fn=<CopyBackwards>)\n",
      "tensor(54.6592, grad_fn=<CopyBackwards>)\n",
      "tensor(54.1888, grad_fn=<CopyBackwards>)\n",
      "tensor(58.7556, grad_fn=<CopyBackwards>)\n",
      "tensor(129.6986, grad_fn=<CopyBackwards>)\n",
      "tensor(123.0264, grad_fn=<CopyBackwards>)\n",
      "tensor(90.4446, grad_fn=<CopyBackwards>)\n",
      "tensor(74.6078, grad_fn=<CopyBackwards>)\n",
      "tensor(123.1664, grad_fn=<CopyBackwards>)\n",
      "tensor(69.8887, grad_fn=<CopyBackwards>)\n",
      "tensor(59.4817, grad_fn=<CopyBackwards>)\n",
      "tensor(60.4532, grad_fn=<CopyBackwards>)\n",
      "tensor(302.6796, grad_fn=<CopyBackwards>)\n",
      "tensor(224.7509, grad_fn=<CopyBackwards>)\n",
      "tensor(233.0569, grad_fn=<CopyBackwards>)\n",
      "tensor(322.1426, grad_fn=<CopyBackwards>)\n",
      "tensor(6.9454, grad_fn=<CopyBackwards>)\n",
      "tensor(7.1748, grad_fn=<CopyBackwards>)\n",
      "tensor(8.7004, grad_fn=<CopyBackwards>)\n",
      "tensor(9.5953, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5613, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5298, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5179, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5212, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5956, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5882, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5825, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5949, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5988, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5840, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6042, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5889, grad_fn=<CopyBackwards>)\n",
      "tensor(2.3319, grad_fn=<CopyBackwards>)\n",
      "tensor(2.6981, grad_fn=<CopyBackwards>)\n",
      "tensor(2.7672, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2771, grad_fn=<CopyBackwards>)\n",
      "tensor(8.2003, grad_fn=<CopyBackwards>)\n",
      "tensor(8.6508, grad_fn=<CopyBackwards>)\n",
      "tensor(8.5537, grad_fn=<CopyBackwards>)\n",
      "tensor(7.8233, grad_fn=<CopyBackwards>)\n",
      "tensor(4.1961, grad_fn=<CopyBackwards>)\n",
      "tensor(6.4012, grad_fn=<CopyBackwards>)\n",
      "tensor(3.6050, grad_fn=<CopyBackwards>)\n",
      "tensor(4.3955, grad_fn=<CopyBackwards>)\n",
      "tensor(1.5885, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3391, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4998, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4851, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5812, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5137, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6883, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7239, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6437, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7179, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7364, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7435, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7182, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7364, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7435, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7200, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7250, grad_fn=<CopyBackwards>)\n",
      "tensor(0.7301, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6644, grad_fn=<CopyBackwards>)\n",
      "tensor(0.5865, grad_fn=<CopyBackwards>)\n",
      "tensor(0.6457, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4774, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3649, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3190, grad_fn=<CopyBackwards>)\n",
      "tensor(0.3650, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4013, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4661, grad_fn=<CopyBackwards>)\n",
      "tensor(0.4283, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9692, grad_fn=<CopyBackwards>)\n",
      "tensor(1.0060, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9889, grad_fn=<CopyBackwards>)\n",
      "tensor(0.9170, grad_fn=<CopyBackwards>)\n",
      "tensor(1.5280, grad_fn=<CopyBackwards>)\n",
      "tensor(1.5111, grad_fn=<CopyBackwards>)\n",
      "tensor(1.4994, grad_fn=<CopyBackwards>)\n",
      "tensor(1.5017, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9473, grad_fn=<CopyBackwards>)\n",
      "tensor(2.0567, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2003, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2112, grad_fn=<CopyBackwards>)\n",
      "tensor(2.5713, grad_fn=<CopyBackwards>)\n",
      "tensor(2.9197, grad_fn=<CopyBackwards>)\n",
      "tensor(2.9340, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2354, grad_fn=<CopyBackwards>)\n",
      "tensor(3.5875, grad_fn=<CopyBackwards>)\n",
      "tensor(3.6043, grad_fn=<CopyBackwards>)\n",
      "tensor(2.5039, grad_fn=<CopyBackwards>)\n",
      "tensor(2.1089, grad_fn=<CopyBackwards>)\n",
      "tensor(4.0231, grad_fn=<CopyBackwards>)\n",
      "tensor(2.7186, grad_fn=<CopyBackwards>)\n",
      "tensor(2.2632, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4698, grad_fn=<CopyBackwards>)\n",
      "tensor(2.8350, grad_fn=<CopyBackwards>)\n",
      "tensor(2.3418, grad_fn=<CopyBackwards>)\n",
      "tensor(2.5616, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9208, grad_fn=<CopyBackwards>)\n",
      "tensor(2.3181, grad_fn=<CopyBackwards>)\n",
      "tensor(2.5492, grad_fn=<CopyBackwards>)\n",
      "tensor(1.9027, grad_fn=<CopyBackwards>)\n",
      "tensor(2.4719, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4453, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericliu/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#X55sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m l_r \u001b[39m=\u001b[39m \u001b[39m0.02\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#X55sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/ML-Side-Project-HTS-Forecasting/notebook/feature_generation_training.ipynb#X55sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m proption_model\u001b[39m.\u001b[39;49mtrain_model(p_model, input_tensor, target_tensor, n_epochs, target_len, batch_size, l_r,)\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/src/proption_model.py:452\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, input_tensor, target_tensor, n_epochs, target_len, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    449\u001b[0m target \u001b[39m=\u001b[39m target_batch[batch_index, :, :, :] \n\u001b[1;32m    450\u001b[0m \u001b[39m#print(input.shape)\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m output, decoder_ouputs, value \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(target_len, \u001b[39minput\u001b[39;49m)\n\u001b[1;32m    453\u001b[0m decoder_batch_ouputs[batch_index] \u001b[39m=\u001b[39m decoder_ouputs \n\u001b[1;32m    454\u001b[0m attention_batch_outputs[batch_index] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/src/proption_model.py:363\u001b[0m, in \u001b[0;36mproportion_model.forward\u001b[0;34m(self, target_len, input)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m) \n\u001b[1;32m    362\u001b[0m \u001b[39m# forward prop - LSTM encoder \u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m encoder_ouput, ( encoder_hn, encoder_cn,) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_lstm\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m) \n\u001b[1;32m    364\u001b[0m encoder_cache \u001b[39m=\u001b[39m (encoder_hn, encoder_cn) \n\u001b[1;32m    366\u001b[0m \u001b[39m# last timestamp from the input\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/ML-Side-Project-HTS-Forecasting/src/proption_model.py:131\u001b[0m, in \u001b[0;36mencoder_lstm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, ):\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    : param x :                    input of shape (# in batch, seq_len, lstm_input_dim)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m    :                              element in the sequence\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     encoder_ouptut, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x,)\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn)\n\u001b[1;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m encoder_ouptut, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    763\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m format_list(extract_stack(f, limit\u001b[39m=\u001b[39;49mlimit))\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n\u001b[1;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m result:\n\u001b[0;32m--> 366\u001b[0m         f\u001b[39m.\u001b[39;49mline\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39;49mgetline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineno)\u001b[39m.\u001b[39;49mstrip()\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### convert np array into torch array \n",
    "input_tensor = torch.tensor(input_array).float()\n",
    "target_tensor = torch.tensor(target_array).float()\n",
    "\n",
    "###---------- dimension on the model hypter-parameters from the paper ------------ ######\n",
    "no_child = 3060 \n",
    "num_hts_embedd = no_child\n",
    "hts_embedd_dim = 8\n",
    "covariate_dim = 0\n",
    "\n",
    "lstm_input_dim = 2 + covariate_dim + hts_embedd_dim\n",
    "lstm_hidden_dim = 48\n",
    "lstm_num_layer = 1\n",
    "lstm_output_dim = 64\n",
    "\n",
    "mha_embedd_dim = lstm_output_dim\n",
    "num_head = 4\n",
    "num_attention_layer = 1\n",
    "mha_output_dim = mha_embedd_dim\n",
    "residual_output_dim = mha_output_dim\n",
    "model_ouput_dim = 1\n",
    "\n",
    "# define the model object\n",
    "p_model = proption_model.proportion_model(\n",
    "    num_hts_embedd,\n",
    "    hts_embedd_dim,  # ts embedding hyper pars\n",
    "    lstm_input_dim,\n",
    "    lstm_hidden_dim,\n",
    "    lstm_num_layer,\n",
    "    lstm_output_dim,  # lstm hyper pars\n",
    "    mha_embedd_dim,\n",
    "    num_head,\n",
    "    num_attention_layer,  # mha hyper pars\n",
    "    mha_output_dim,\n",
    "    residual_output_dim,  # skip connection hyper pars\n",
    "    model_ouput_dim,  # output later hyper pars\n",
    ")\n",
    "\n",
    "###---------- trainign parameters from the paper ------------ ######\n",
    "n_epochs = 50\n",
    "target_len = Forward\n",
    "batch_size = 4\n",
    "l_r = 0.02\n",
    "\n",
    "# start training\n",
    "proption_model.train_model(p_model, input_tensor, target_tensor, n_epochs, target_len, batch_size, l_r,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## PROD CODE FOLLOWING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_id  dept_id      item_id  id\n",
       "0  FOODS  FOODS_1  FOODS_1_001  10\n",
       "1  FOODS  FOODS_1  FOODS_1_002  10\n",
       "2  FOODS  FOODS_1  FOODS_1_003  10\n",
       "3  FOODS  FOODS_1  FOODS_1_004  10\n",
       "4  FOODS  FOODS_1  FOODS_1_005  10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_prod = sales_train_validation.groupby(groupby_list[2:]).count()[['id']].reset_index()\n",
    "hl_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = hl_prod\n",
    "df_right = sales_train_validation.groupby('item_id').sum()\n",
    "df = df_left.merge(df_right, left_on='item_id', right_index=True, how='inner').drop(columns=['id'])\n",
    "df.rename(columns=d_to_date, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>2011-01-29</th>\n",
       "      <th>2011-01-30</th>\n",
       "      <th>2011-01-31</th>\n",
       "      <th>2011-02-01</th>\n",
       "      <th>2011-02-02</th>\n",
       "      <th>2011-02-03</th>\n",
       "      <th>2011-02-04</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-04-15</th>\n",
       "      <th>2016-04-16</th>\n",
       "      <th>2016-04-17</th>\n",
       "      <th>2016-04-18</th>\n",
       "      <th>2016-04-19</th>\n",
       "      <th>2016-04-20</th>\n",
       "      <th>2016-04-21</th>\n",
       "      <th>2016-04-22</th>\n",
       "      <th>2016-04-23</th>\n",
       "      <th>2016-04-24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_512</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_514</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3049 rows × 1916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat_id      dept_id          item_id  2011-01-29  2011-01-30  \\\n",
       "0         FOODS      FOODS_1      FOODS_1_001           6           6   \n",
       "1         FOODS      FOODS_1      FOODS_1_002           4           5   \n",
       "2         FOODS      FOODS_1      FOODS_1_003          14           8   \n",
       "3         FOODS      FOODS_1      FOODS_1_004           0           0   \n",
       "4         FOODS      FOODS_1      FOODS_1_005          34          32   \n",
       "...         ...          ...              ...         ...         ...   \n",
       "3044  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_512           5           4   \n",
       "3045  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_513           0           0   \n",
       "3046  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_514           4           8   \n",
       "3047  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_515           0           0   \n",
       "3048  HOUSEHOLD  HOUSEHOLD_2  HOUSEHOLD_2_516           2           4   \n",
       "\n",
       "      2011-01-31  2011-02-01  2011-02-02  2011-02-03  2011-02-04  ...  \\\n",
       "0              4           6           7          18          10  ...   \n",
       "1              7           4           3           4           1  ...   \n",
       "2              3           6           3           8          13  ...   \n",
       "3              0           0           0           0           0  ...   \n",
       "4             13          20          10          21          18  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "3044           1           3           2           4           2  ...   \n",
       "3045           0           0           0           0           0  ...   \n",
       "3046           2           1           1           2           3  ...   \n",
       "3047           0           0           0           0           0  ...   \n",
       "3048           0           3           1           2           2  ...   \n",
       "\n",
       "      2016-04-15  2016-04-16  2016-04-17  2016-04-18  2016-04-19  2016-04-20  \\\n",
       "0              4           4          30           7           5           3   \n",
       "1              5           9           4           1           3           5   \n",
       "2              7           3           5           6           3           4   \n",
       "3              0           0           0           0           0           0   \n",
       "4             16          14          14          18          18          27   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3044           6           7           9          13          12           2   \n",
       "3045           9           3           3           3           2           4   \n",
       "3046           1           2           2           0           1           0   \n",
       "3047           1           3           2           0           0           1   \n",
       "3048           4           1           1           0           0           1   \n",
       "\n",
       "      2016-04-21  2016-04-22  2016-04-23  2016-04-24  \n",
       "0              6           2          16           6  \n",
       "1              5           3           3           1  \n",
       "2              4           3          11           5  \n",
       "3              0           0           0           0  \n",
       "4             12          15          38           9  \n",
       "...          ...         ...         ...         ...  \n",
       "3044           8           6          10           5  \n",
       "3045           6           7           4          11  \n",
       "3046           0           2           2           2  \n",
       "3047           1           1           5           1  \n",
       "3048           2           1           0           1  \n",
       "\n",
       "[3049 rows x 1916 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time related covariates: \n",
    "\n",
    "- Wehther it is weekend/not, we observed sales are high overweekend across three categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [d_to_date[d] for d in sales_train_validation.columns[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statrting date is 2011-01-29\n",
      "The statrting date is 2016-04-24\n"
     ]
    }
   ],
   "source": [
    "print(f'The statrting date is {date[0]}')\n",
    "print(f'The statrting date is {date[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given data is weekday.\n"
     ]
    }
   ],
   "source": [
    "d = datetime.strptime(date[2], '%Y-%m-%d')\n",
    "if d.weekday() > 4:\n",
    "    print ('Given date is weekend.')\n",
    "else:\n",
    "    print ('Given data is weekday.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913\n"
     ]
    }
   ],
   "source": [
    "weekend_binary = [1 if (datetime.strptime(d, '%Y-%m-%d')).weekday() > 4 else 0 for d in date]\n",
    "print(len(weekend_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 30490)\n"
     ]
    }
   ],
   "source": [
    "stv = sales_train_validation[sales_train_validation.columns[6:]]\n",
    "stv = stv.T\n",
    "print(stv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stv.sum(axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "hie_index = torch.arange(stv.shape[1])\n",
    "\n",
    "hie_index_2d = hie_index.expand(stv.shape[0], stv.shape[1])\n",
    "\n",
    "hie_index_3d = hie_index_2d.reshape(\n",
    "    hie_index_2d.shape[0], hie_index_2d.shape[-1], 1\n",
    ")\n",
    "\n",
    "print(hie_index_3d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913.0\n",
      "(1913, 30490, 1)\n",
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "stv_proportions = np.divide(stv.values, stv.sum(axis=1).values.reshape(-1,1))\n",
    "print(stv_proportions.sum(axis=1).sum())\n",
    "\n",
    "stv_proportions_3d = stv_proportions.reshape(stv_proportions.shape[0], stv_proportions.shape[1], 1)\n",
    "print(stv_proportions_3d.shape)\n",
    "\n",
    "proportions_tensor = torch.tensor(stv_proportions_3d)\n",
    "print(proportions_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n",
      "tensor([1])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weekend_binary_tensor = torch.tensor(weekend_binary).unsqueeze_(-1).unsqueeze_(-1)\n",
    "weekend_binary_tensor = weekend_binary_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], weekend_binary_tensor.shape[-1])\n",
    "print(weekend_binary_tensor.shape)\n",
    "print(weekend_binary_tensor[1,0])\n",
    "print(weekend_binary_tensor[2,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "parent_sales_tensor = torch.tensor(parent_sales).unsqueeze_(-1).unsqueeze_(-1)\n",
    "parent_sales_tensor = parent_sales_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], parent_sales_tensor.shape[-1])\n",
    "print(parent_sales_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 4])\n"
     ]
    }
   ],
   "source": [
    "data_3d = torch.cat((proportions_tensor, parent_sales_tensor,weekend_binary_tensor, hie_index_3d), -1)\n",
    "data_3d = data_3d.double()\n",
    "print(data_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1858, 56, 30490, 4])\n",
      "torch.Size([56, 30490, 4])\n",
      "data correctly processed to generate time-bacted tensor\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n",
      "Entering the training pipeline\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "# dimension about the dataset\n",
    "no_child = proportions_tensor.shape[1]\n",
    "History = 28\n",
    "Forward = 28\n",
    "\n",
    "number_observations = data_3d.shape[0] - (History + Forward) + 1\n",
    "\n",
    "data_3d_time_batched = torch.empty(\n",
    "    number_observations, History + Forward, data_3d.shape[1], data_3d.shape[2]\n",
    ")\n",
    "\n",
    "for i in range(number_observations):\n",
    "\n",
    "    data_3d_time_batched[i, :, :, :] = data_3d[i : i + History + Forward, :, :]\n",
    "\n",
    "print(data_3d_time_batched.shape)\n",
    "print(data_3d_time_batched[-1,:,:,:].shape)\n",
    "\n",
    "\n",
    "#if torch.equal(data_3d_time_batched[-1, -1, :, :].double(), data_3d[-1, :, :].double()):\n",
    "\n",
    "print(\"data correctly processed to generate time-bacted tensor\")\n",
    "\n",
    "input_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    History,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    data_3d_time_batched.shape[-1],\n",
    ")\n",
    "\n",
    "## We first use the recursive predicitng mechanism in LSTM, in the future we release more blocks that adapt to teacher-forcing/mixed training\n",
    "target_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    Forward,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    1\n",
    "    # data_3d_time_batched.shape[-1]\n",
    ")\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "\n",
    "print(\"Entering the training pipeline\")\n",
    "\n",
    "for i in range(data_3d_time_batched.shape[0]):\n",
    "\n",
    "    input_tensor[i] = data_3d_time_batched[i, :History, :, :]\n",
    "    target_2d = data_3d_time_batched[i, History:, :, 0]\n",
    "    target_tensor[i] = target_2d.reshape(\n",
    "        target_2d.shape[0], target_2d.shape[1], 1\n",
    "    )\n",
    "\n",
    "    # print(input_tensor.shape)\n",
    "    # print(target_tensor.shape)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "    # print(target_tensor[-1,0,:,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 12, got 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericliu/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/notebook/feature_generation.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=38'>39</a>\u001b[0m l_r \u001b[39m=\u001b[39m \u001b[39m0.00079\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=40'>41</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=41'>42</a>\u001b[0m p_model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=42'>43</a>\u001b[0m     input_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=43'>44</a>\u001b[0m     target_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=44'>45</a>\u001b[0m     n_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=45'>46</a>\u001b[0m     target_len,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=46'>47</a>\u001b[0m     batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=47'>48</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49ml_r,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=48'>49</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:425\u001b[0m, in \u001b[0;36mproportion_model.train\u001b[0;34m(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m cat((\u001b[39minput\u001b[39m, embedd_vector), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[39m# print(f\"with ENCODED hierachy, input batch diemsion is {input.shape}\")\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[39m## ------------ lstm encoder ---input: L, C, input_dim ---------- ##\u001b[39;00m\n\u001b[1;32m    422\u001b[0m encoder_ouput, (\n\u001b[1;32m    423\u001b[0m     encoder_hn,\n\u001b[1;32m    424\u001b[0m     encoder_cn,\n\u001b[0;32m--> 425\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_lstm\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m, h0, c0)\n\u001b[1;32m    426\u001b[0m encoder_cache \u001b[39m=\u001b[39m (encoder_hn, encoder_cn)\n\u001b[1;32m    427\u001b[0m \u001b[39m# print(f\"The encoder final hidden state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# print(f\"The encoder final cell state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[39m## ------------- lstm ddecoder --------L, C, input_dim ----------- ##\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:119\u001b[0m, in \u001b[0;36mencoder_lstm.forward\u001b[0;34m(self, x, h0, c0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h0, c0):\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m    : param x :                    input of shape (# in batch, seq_len, lstm_input_dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    :                              element in the sequence\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     encoder_ouptut, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m encoder_ouptut, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 759\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:684\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    680\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    683\u001b[0m                        ):\n\u001b[0;32m--> 684\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    685\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    686\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    687\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    688\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 12, got 11"
     ]
    }
   ],
   "source": [
    "###---------- dimension on the model hypter-parameters from the paper ------------ ######\n",
    "num_hts_embedd = no_child\n",
    "hts_embedd_dim = 8\n",
    "covariate_dim = 2 \n",
    "\n",
    "lstm_input_dim = 2 + covariate_dim + hts_embedd_dim\n",
    "lstm_hidden_dim = 48\n",
    "lstm_num_layer = 1\n",
    "lstm_output_dim = 64\n",
    "\n",
    "mha_embedd_dim = lstm_output_dim\n",
    "num_head = 4\n",
    "num_attention_layer = 1\n",
    "mha_output_dim = mha_embedd_dim\n",
    "residual_output_dim = mha_output_dim\n",
    "model_ouput_dim = 1\n",
    "\n",
    "# define the model object\n",
    "p_model = proportion_model(\n",
    "    num_hts_embedd,\n",
    "    hts_embedd_dim,  # ts embedding hyper pars\n",
    "    lstm_input_dim,\n",
    "    lstm_hidden_dim,\n",
    "    lstm_num_layer,\n",
    "    lstm_output_dim,  # lstm hyper pars\n",
    "    mha_embedd_dim,\n",
    "    num_head,\n",
    "    num_attention_layer,  # mha hyper pars\n",
    "    mha_output_dim,\n",
    "    residual_output_dim,  # skip connection hyper pars\n",
    "    model_ouput_dim,  # output later hyper pars\n",
    ")\n",
    "\n",
    "###---------- trainign parameters from the paper ------------ ######\n",
    "\n",
    "n_epochs = 50\n",
    "target_len = Forward\n",
    "batch_size = 4\n",
    "l_r = 0.00079\n",
    "\n",
    "# start training\n",
    "p_model.train(\n",
    "    input_tensor,\n",
    "    target_tensor,\n",
    "    n_epochs,\n",
    "    target_len,\n",
    "    batch_size,\n",
    "    learning_rate=l_r,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
